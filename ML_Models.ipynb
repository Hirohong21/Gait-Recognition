{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Custom Model Using Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_coords_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19089 entries, 0 to 19088\n",
      "Columns: 133 entries, Class to v33\n",
      "dtypes: float64(132), object(1)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fyc</td>\n",
       "      <td>0.879743</td>\n",
       "      <td>0.434765</td>\n",
       "      <td>-0.110076</td>\n",
       "      <td>0.998767</td>\n",
       "      <td>0.884691</td>\n",
       "      <td>0.423257</td>\n",
       "      <td>-0.112526</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.887720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163869</td>\n",
       "      <td>0.858926</td>\n",
       "      <td>0.875535</td>\n",
       "      <td>0.894358</td>\n",
       "      <td>-0.074822</td>\n",
       "      <td>0.946482</td>\n",
       "      <td>0.815601</td>\n",
       "      <td>0.877874</td>\n",
       "      <td>0.101090</td>\n",
       "      <td>0.892224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fyc</td>\n",
       "      <td>0.875687</td>\n",
       "      <td>0.434991</td>\n",
       "      <td>-0.121108</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>0.881445</td>\n",
       "      <td>0.424194</td>\n",
       "      <td>-0.120181</td>\n",
       "      <td>0.998495</td>\n",
       "      <td>0.884622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164102</td>\n",
       "      <td>0.858729</td>\n",
       "      <td>0.871622</td>\n",
       "      <td>0.894546</td>\n",
       "      <td>-0.070210</td>\n",
       "      <td>0.946372</td>\n",
       "      <td>0.789716</td>\n",
       "      <td>0.876701</td>\n",
       "      <td>0.109292</td>\n",
       "      <td>0.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fyc</td>\n",
       "      <td>0.865430</td>\n",
       "      <td>0.436499</td>\n",
       "      <td>-0.147009</td>\n",
       "      <td>0.998986</td>\n",
       "      <td>0.870713</td>\n",
       "      <td>0.426487</td>\n",
       "      <td>-0.145864</td>\n",
       "      <td>0.998635</td>\n",
       "      <td>0.873895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142747</td>\n",
       "      <td>0.857340</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>0.894528</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.945344</td>\n",
       "      <td>0.760859</td>\n",
       "      <td>0.870030</td>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.892033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fyc</td>\n",
       "      <td>0.855601</td>\n",
       "      <td>0.439941</td>\n",
       "      <td>-0.162105</td>\n",
       "      <td>0.999083</td>\n",
       "      <td>0.861209</td>\n",
       "      <td>0.430437</td>\n",
       "      <td>-0.159268</td>\n",
       "      <td>0.998765</td>\n",
       "      <td>0.864392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127017</td>\n",
       "      <td>0.856817</td>\n",
       "      <td>0.872124</td>\n",
       "      <td>0.894467</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.942292</td>\n",
       "      <td>0.739511</td>\n",
       "      <td>0.865657</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>0.893602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyc</td>\n",
       "      <td>0.839366</td>\n",
       "      <td>0.441057</td>\n",
       "      <td>-0.165840</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.846083</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>-0.166450</td>\n",
       "      <td>0.998884</td>\n",
       "      <td>0.849447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138057</td>\n",
       "      <td>0.851298</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.894467</td>\n",
       "      <td>0.035043</td>\n",
       "      <td>0.942063</td>\n",
       "      <td>0.735843</td>\n",
       "      <td>0.867225</td>\n",
       "      <td>0.077553</td>\n",
       "      <td>0.894663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19084</th>\n",
       "      <td>zyf</td>\n",
       "      <td>0.482226</td>\n",
       "      <td>0.352177</td>\n",
       "      <td>0.072488</td>\n",
       "      <td>0.999090</td>\n",
       "      <td>0.479214</td>\n",
       "      <td>0.347417</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.998431</td>\n",
       "      <td>0.477319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021791</td>\n",
       "      <td>0.932058</td>\n",
       "      <td>0.471075</td>\n",
       "      <td>0.669711</td>\n",
       "      <td>0.032251</td>\n",
       "      <td>0.868960</td>\n",
       "      <td>0.493318</td>\n",
       "      <td>0.677998</td>\n",
       "      <td>-0.013290</td>\n",
       "      <td>0.863955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19085</th>\n",
       "      <td>zyf</td>\n",
       "      <td>0.482570</td>\n",
       "      <td>0.351507</td>\n",
       "      <td>0.071666</td>\n",
       "      <td>0.999083</td>\n",
       "      <td>0.479578</td>\n",
       "      <td>0.346604</td>\n",
       "      <td>0.054295</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>0.477711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.935579</td>\n",
       "      <td>0.474237</td>\n",
       "      <td>0.670260</td>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.872947</td>\n",
       "      <td>0.493696</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>-0.033089</td>\n",
       "      <td>0.872157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19086</th>\n",
       "      <td>zyf</td>\n",
       "      <td>0.482691</td>\n",
       "      <td>0.350844</td>\n",
       "      <td>0.049965</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>0.479861</td>\n",
       "      <td>0.346014</td>\n",
       "      <td>0.035424</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.478057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.938204</td>\n",
       "      <td>0.473171</td>\n",
       "      <td>0.669987</td>\n",
       "      <td>0.044845</td>\n",
       "      <td>0.876245</td>\n",
       "      <td>0.492910</td>\n",
       "      <td>0.670024</td>\n",
       "      <td>-0.022132</td>\n",
       "      <td>0.879208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19087</th>\n",
       "      <td>zyf</td>\n",
       "      <td>0.482893</td>\n",
       "      <td>0.350550</td>\n",
       "      <td>0.076882</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.480153</td>\n",
       "      <td>0.345540</td>\n",
       "      <td>0.062864</td>\n",
       "      <td>0.998147</td>\n",
       "      <td>0.478365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.940749</td>\n",
       "      <td>0.472804</td>\n",
       "      <td>0.667367</td>\n",
       "      <td>0.039189</td>\n",
       "      <td>0.876823</td>\n",
       "      <td>0.489885</td>\n",
       "      <td>0.665885</td>\n",
       "      <td>-0.027317</td>\n",
       "      <td>0.884802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19088</th>\n",
       "      <td>zyf</td>\n",
       "      <td>0.483096</td>\n",
       "      <td>0.350540</td>\n",
       "      <td>0.078826</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>0.480336</td>\n",
       "      <td>0.345481</td>\n",
       "      <td>0.064392</td>\n",
       "      <td>0.998110</td>\n",
       "      <td>0.478531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.943269</td>\n",
       "      <td>0.471631</td>\n",
       "      <td>0.664478</td>\n",
       "      <td>0.048995</td>\n",
       "      <td>0.877981</td>\n",
       "      <td>0.488357</td>\n",
       "      <td>0.664457</td>\n",
       "      <td>-0.023956</td>\n",
       "      <td>0.890476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19089 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class        x1        y1        z1        v1        x2        y2  \\\n",
       "0       fyc  0.879743  0.434765 -0.110076  0.998767  0.884691  0.423257   \n",
       "1       fyc  0.875687  0.434991 -0.121108  0.998882  0.881445  0.424194   \n",
       "2       fyc  0.865430  0.436499 -0.147009  0.998986  0.870713  0.426487   \n",
       "3       fyc  0.855601  0.439941 -0.162105  0.999083  0.861209  0.430437   \n",
       "4       fyc  0.839366  0.441057 -0.165840  0.999171  0.846083  0.431095   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "19084   zyf  0.482226  0.352177  0.072488  0.999090  0.479214  0.347417   \n",
       "19085   zyf  0.482570  0.351507  0.071666  0.999083  0.479578  0.346604   \n",
       "19086   zyf  0.482691  0.350844  0.049965  0.999033  0.479861  0.346014   \n",
       "19087   zyf  0.482893  0.350550  0.076882  0.998906  0.480153  0.345540   \n",
       "19088   zyf  0.483096  0.350540  0.078826  0.998881  0.480336  0.345481   \n",
       "\n",
       "             z2        v2        x3  ...       z31       v31       x32  \\\n",
       "0     -0.112526  0.998340  0.887720  ...  0.163869  0.858926  0.875535   \n",
       "1     -0.120181  0.998495  0.884622  ...  0.164102  0.858729  0.871622   \n",
       "2     -0.145864  0.998635  0.873895  ...  0.142747  0.857340  0.871901   \n",
       "3     -0.159268  0.998765  0.864392  ...  0.127017  0.856817  0.872124   \n",
       "4     -0.166450  0.998884  0.849447  ...  0.138057  0.851298  0.872283   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19084  0.055533  0.998431  0.477319  ...  0.021791  0.932058  0.471075   \n",
       "19085  0.054295  0.998416  0.477711  ...  0.002978  0.935579  0.474237   \n",
       "19086  0.035424  0.998326  0.478057  ...  0.014861  0.938204  0.473171   \n",
       "19087  0.062864  0.998147  0.478365  ...  0.005521  0.940749  0.472804   \n",
       "19088  0.064392  0.998110  0.478531  ...  0.009278  0.943269  0.471631   \n",
       "\n",
       "            y32       z32       v32       x33       y33       z33       v33  \n",
       "0      0.894358 -0.074822  0.946482  0.815601  0.877874  0.101090  0.892224  \n",
       "1      0.894546 -0.070210  0.946372  0.789716  0.876701  0.109292  0.890800  \n",
       "2      0.894528  0.004848  0.945344  0.760859  0.870030  0.086790  0.892033  \n",
       "3      0.894467  0.018772  0.942292  0.739511  0.865657  0.067528  0.893602  \n",
       "4      0.894467  0.035043  0.942063  0.735843  0.867225  0.077553  0.894663  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "19084  0.669711  0.032251  0.868960  0.493318  0.677998 -0.013290  0.863955  \n",
       "19085  0.670260  0.047835  0.872947  0.493696  0.673325 -0.033089  0.872157  \n",
       "19086  0.669987  0.044845  0.876245  0.492910  0.670024 -0.022132  0.879208  \n",
       "19087  0.667367  0.039189  0.876823  0.489885  0.665885 -0.027317  0.884802  \n",
       "19088  0.664478  0.048995  0.877981  0.488357  0.664457 -0.023956  0.890476  \n",
       "\n",
       "[19089 rows x 133 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1) # features\n",
    "Y = df['Class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.879743</td>\n",
       "      <td>0.434765</td>\n",
       "      <td>-0.110076</td>\n",
       "      <td>0.998767</td>\n",
       "      <td>0.884691</td>\n",
       "      <td>0.423257</td>\n",
       "      <td>-0.112526</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.887720</td>\n",
       "      <td>0.422654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163869</td>\n",
       "      <td>0.858926</td>\n",
       "      <td>0.875535</td>\n",
       "      <td>0.894358</td>\n",
       "      <td>-0.074822</td>\n",
       "      <td>0.946482</td>\n",
       "      <td>0.815601</td>\n",
       "      <td>0.877874</td>\n",
       "      <td>0.101090</td>\n",
       "      <td>0.892224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875687</td>\n",
       "      <td>0.434991</td>\n",
       "      <td>-0.121108</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>0.881445</td>\n",
       "      <td>0.424194</td>\n",
       "      <td>-0.120181</td>\n",
       "      <td>0.998495</td>\n",
       "      <td>0.884622</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164102</td>\n",
       "      <td>0.858729</td>\n",
       "      <td>0.871622</td>\n",
       "      <td>0.894546</td>\n",
       "      <td>-0.070210</td>\n",
       "      <td>0.946372</td>\n",
       "      <td>0.789716</td>\n",
       "      <td>0.876701</td>\n",
       "      <td>0.109292</td>\n",
       "      <td>0.890800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.865430</td>\n",
       "      <td>0.436499</td>\n",
       "      <td>-0.147009</td>\n",
       "      <td>0.998986</td>\n",
       "      <td>0.870713</td>\n",
       "      <td>0.426487</td>\n",
       "      <td>-0.145864</td>\n",
       "      <td>0.998635</td>\n",
       "      <td>0.873895</td>\n",
       "      <td>0.426269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142747</td>\n",
       "      <td>0.857340</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>0.894528</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.945344</td>\n",
       "      <td>0.760859</td>\n",
       "      <td>0.870030</td>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.892033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.855601</td>\n",
       "      <td>0.439941</td>\n",
       "      <td>-0.162105</td>\n",
       "      <td>0.999083</td>\n",
       "      <td>0.861209</td>\n",
       "      <td>0.430437</td>\n",
       "      <td>-0.159268</td>\n",
       "      <td>0.998765</td>\n",
       "      <td>0.864392</td>\n",
       "      <td>0.430636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127017</td>\n",
       "      <td>0.856817</td>\n",
       "      <td>0.872124</td>\n",
       "      <td>0.894467</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.942292</td>\n",
       "      <td>0.739511</td>\n",
       "      <td>0.865657</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>0.893602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.839366</td>\n",
       "      <td>0.441057</td>\n",
       "      <td>-0.165840</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.846083</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>-0.166450</td>\n",
       "      <td>0.998884</td>\n",
       "      <td>0.849447</td>\n",
       "      <td>0.431234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138057</td>\n",
       "      <td>0.851298</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.894467</td>\n",
       "      <td>0.035043</td>\n",
       "      <td>0.942063</td>\n",
       "      <td>0.735843</td>\n",
       "      <td>0.867225</td>\n",
       "      <td>0.077553</td>\n",
       "      <td>0.894663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19084</th>\n",
       "      <td>0.482226</td>\n",
       "      <td>0.352177</td>\n",
       "      <td>0.072488</td>\n",
       "      <td>0.999090</td>\n",
       "      <td>0.479214</td>\n",
       "      <td>0.347417</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.998431</td>\n",
       "      <td>0.477319</td>\n",
       "      <td>0.347516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021791</td>\n",
       "      <td>0.932058</td>\n",
       "      <td>0.471075</td>\n",
       "      <td>0.669711</td>\n",
       "      <td>0.032251</td>\n",
       "      <td>0.868960</td>\n",
       "      <td>0.493318</td>\n",
       "      <td>0.677998</td>\n",
       "      <td>-0.013290</td>\n",
       "      <td>0.863955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19085</th>\n",
       "      <td>0.482570</td>\n",
       "      <td>0.351507</td>\n",
       "      <td>0.071666</td>\n",
       "      <td>0.999083</td>\n",
       "      <td>0.479578</td>\n",
       "      <td>0.346604</td>\n",
       "      <td>0.054295</td>\n",
       "      <td>0.998416</td>\n",
       "      <td>0.477711</td>\n",
       "      <td>0.346627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.935579</td>\n",
       "      <td>0.474237</td>\n",
       "      <td>0.670260</td>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.872947</td>\n",
       "      <td>0.493696</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>-0.033089</td>\n",
       "      <td>0.872157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19086</th>\n",
       "      <td>0.482691</td>\n",
       "      <td>0.350844</td>\n",
       "      <td>0.049965</td>\n",
       "      <td>0.999033</td>\n",
       "      <td>0.479861</td>\n",
       "      <td>0.346014</td>\n",
       "      <td>0.035424</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.478057</td>\n",
       "      <td>0.345983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.938204</td>\n",
       "      <td>0.473171</td>\n",
       "      <td>0.669987</td>\n",
       "      <td>0.044845</td>\n",
       "      <td>0.876245</td>\n",
       "      <td>0.492910</td>\n",
       "      <td>0.670024</td>\n",
       "      <td>-0.022132</td>\n",
       "      <td>0.879208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19087</th>\n",
       "      <td>0.482893</td>\n",
       "      <td>0.350550</td>\n",
       "      <td>0.076882</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.480153</td>\n",
       "      <td>0.345540</td>\n",
       "      <td>0.062864</td>\n",
       "      <td>0.998147</td>\n",
       "      <td>0.478365</td>\n",
       "      <td>0.345432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.940749</td>\n",
       "      <td>0.472804</td>\n",
       "      <td>0.667367</td>\n",
       "      <td>0.039189</td>\n",
       "      <td>0.876823</td>\n",
       "      <td>0.489885</td>\n",
       "      <td>0.665885</td>\n",
       "      <td>-0.027317</td>\n",
       "      <td>0.884802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19088</th>\n",
       "      <td>0.483096</td>\n",
       "      <td>0.350540</td>\n",
       "      <td>0.078826</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>0.480336</td>\n",
       "      <td>0.345481</td>\n",
       "      <td>0.064392</td>\n",
       "      <td>0.998110</td>\n",
       "      <td>0.478531</td>\n",
       "      <td>0.345345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.943269</td>\n",
       "      <td>0.471631</td>\n",
       "      <td>0.664478</td>\n",
       "      <td>0.048995</td>\n",
       "      <td>0.877981</td>\n",
       "      <td>0.488357</td>\n",
       "      <td>0.664457</td>\n",
       "      <td>-0.023956</td>\n",
       "      <td>0.890476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19089 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        y1        z1        v1        x2        y2        z2  \\\n",
       "0      0.879743  0.434765 -0.110076  0.998767  0.884691  0.423257 -0.112526   \n",
       "1      0.875687  0.434991 -0.121108  0.998882  0.881445  0.424194 -0.120181   \n",
       "2      0.865430  0.436499 -0.147009  0.998986  0.870713  0.426487 -0.145864   \n",
       "3      0.855601  0.439941 -0.162105  0.999083  0.861209  0.430437 -0.159268   \n",
       "4      0.839366  0.441057 -0.165840  0.999171  0.846083  0.431095 -0.166450   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19084  0.482226  0.352177  0.072488  0.999090  0.479214  0.347417  0.055533   \n",
       "19085  0.482570  0.351507  0.071666  0.999083  0.479578  0.346604  0.054295   \n",
       "19086  0.482691  0.350844  0.049965  0.999033  0.479861  0.346014  0.035424   \n",
       "19087  0.482893  0.350550  0.076882  0.998906  0.480153  0.345540  0.062864   \n",
       "19088  0.483096  0.350540  0.078826  0.998881  0.480336  0.345481  0.064392   \n",
       "\n",
       "             v2        x3        y3  ...       z31       v31       x32  \\\n",
       "0      0.998340  0.887720  0.422654  ...  0.163869  0.858926  0.875535   \n",
       "1      0.998495  0.884622  0.423800  ...  0.164102  0.858729  0.871622   \n",
       "2      0.998635  0.873895  0.426269  ...  0.142747  0.857340  0.871901   \n",
       "3      0.998765  0.864392  0.430636  ...  0.127017  0.856817  0.872124   \n",
       "4      0.998884  0.849447  0.431234  ...  0.138057  0.851298  0.872283   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19084  0.998431  0.477319  0.347516  ...  0.021791  0.932058  0.471075   \n",
       "19085  0.998416  0.477711  0.346627  ...  0.002978  0.935579  0.474237   \n",
       "19086  0.998326  0.478057  0.345983  ...  0.014861  0.938204  0.473171   \n",
       "19087  0.998147  0.478365  0.345432  ...  0.005521  0.940749  0.472804   \n",
       "19088  0.998110  0.478531  0.345345  ...  0.009278  0.943269  0.471631   \n",
       "\n",
       "            y32       z32       v32       x33       y33       z33       v33  \n",
       "0      0.894358 -0.074822  0.946482  0.815601  0.877874  0.101090  0.892224  \n",
       "1      0.894546 -0.070210  0.946372  0.789716  0.876701  0.109292  0.890800  \n",
       "2      0.894528  0.004848  0.945344  0.760859  0.870030  0.086790  0.892033  \n",
       "3      0.894467  0.018772  0.942292  0.739511  0.865657  0.067528  0.893602  \n",
       "4      0.894467  0.035043  0.942063  0.735843  0.867225  0.077553  0.894663  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "19084  0.669711  0.032251  0.868960  0.493318  0.677998 -0.013290  0.863955  \n",
       "19085  0.670260  0.047835  0.872947  0.493696  0.673325 -0.033089  0.872157  \n",
       "19086  0.669987  0.044845  0.876245  0.492910  0.670024 -0.022132  0.879208  \n",
       "19087  0.667367  0.039189  0.876823  0.489885  0.665885 -0.027317  0.884802  \n",
       "19088  0.664478  0.048995  0.877981  0.488357  0.664457 -0.023956  0.890476  \n",
       "\n",
       "[19089 rows x 132 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        fyc\n",
       "1        fyc\n",
       "2        fyc\n",
       "3        fyc\n",
       "4        fyc\n",
       "        ... \n",
       "19084    zyf\n",
       "19085    zyf\n",
       "19086    zyf\n",
       "19087    zyf\n",
       "19088    zyf\n",
       "Name: Class, Length: 19089, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16392</th>\n",
       "      <td>0.423033</td>\n",
       "      <td>0.243220</td>\n",
       "      <td>-0.166562</td>\n",
       "      <td>0.998948</td>\n",
       "      <td>0.420859</td>\n",
       "      <td>0.225468</td>\n",
       "      <td>-0.153010</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.419460</td>\n",
       "      <td>0.223927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167936</td>\n",
       "      <td>0.958910</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.776824</td>\n",
       "      <td>0.403006</td>\n",
       "      <td>0.926374</td>\n",
       "      <td>0.315292</td>\n",
       "      <td>0.808001</td>\n",
       "      <td>0.084077</td>\n",
       "      <td>0.977447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18350</th>\n",
       "      <td>0.577514</td>\n",
       "      <td>0.340552</td>\n",
       "      <td>-0.063475</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.575350</td>\n",
       "      <td>0.325915</td>\n",
       "      <td>-0.050898</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.574365</td>\n",
       "      <td>0.325517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102997</td>\n",
       "      <td>0.965358</td>\n",
       "      <td>0.522051</td>\n",
       "      <td>0.889323</td>\n",
       "      <td>0.267132</td>\n",
       "      <td>0.940889</td>\n",
       "      <td>0.577008</td>\n",
       "      <td>0.892135</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>0.984337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>0.413423</td>\n",
       "      <td>0.213392</td>\n",
       "      <td>-0.176539</td>\n",
       "      <td>0.999376</td>\n",
       "      <td>0.415025</td>\n",
       "      <td>0.205827</td>\n",
       "      <td>-0.165939</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.414906</td>\n",
       "      <td>0.206057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135663</td>\n",
       "      <td>0.882528</td>\n",
       "      <td>0.416023</td>\n",
       "      <td>0.569303</td>\n",
       "      <td>0.044649</td>\n",
       "      <td>0.839371</td>\n",
       "      <td>0.404568</td>\n",
       "      <td>0.559988</td>\n",
       "      <td>0.068812</td>\n",
       "      <td>0.828603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12233</th>\n",
       "      <td>0.452745</td>\n",
       "      <td>0.376188</td>\n",
       "      <td>-0.164070</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.458794</td>\n",
       "      <td>0.366891</td>\n",
       "      <td>-0.163044</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.461115</td>\n",
       "      <td>0.367140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055015</td>\n",
       "      <td>0.854127</td>\n",
       "      <td>0.499214</td>\n",
       "      <td>0.766801</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.977485</td>\n",
       "      <td>0.375258</td>\n",
       "      <td>0.758957</td>\n",
       "      <td>-0.023410</td>\n",
       "      <td>0.934828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10623</th>\n",
       "      <td>0.428368</td>\n",
       "      <td>0.392361</td>\n",
       "      <td>-0.302119</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.432887</td>\n",
       "      <td>0.381584</td>\n",
       "      <td>-0.284551</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.436236</td>\n",
       "      <td>0.381450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117801</td>\n",
       "      <td>0.817713</td>\n",
       "      <td>0.445228</td>\n",
       "      <td>0.858981</td>\n",
       "      <td>0.289428</td>\n",
       "      <td>0.953463</td>\n",
       "      <td>0.411308</td>\n",
       "      <td>0.919083</td>\n",
       "      <td>-0.001454</td>\n",
       "      <td>0.975376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>0.419237</td>\n",
       "      <td>0.257569</td>\n",
       "      <td>-0.158076</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.423303</td>\n",
       "      <td>0.238311</td>\n",
       "      <td>-0.178791</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.424627</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413721</td>\n",
       "      <td>0.908600</td>\n",
       "      <td>0.493818</td>\n",
       "      <td>0.851053</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>0.990450</td>\n",
       "      <td>0.318970</td>\n",
       "      <td>0.791333</td>\n",
       "      <td>0.361413</td>\n",
       "      <td>0.952832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9449</th>\n",
       "      <td>0.788890</td>\n",
       "      <td>0.213552</td>\n",
       "      <td>-0.194469</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.794791</td>\n",
       "      <td>0.203968</td>\n",
       "      <td>-0.188308</td>\n",
       "      <td>0.999204</td>\n",
       "      <td>0.797630</td>\n",
       "      <td>0.203877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139334</td>\n",
       "      <td>0.868544</td>\n",
       "      <td>0.782560</td>\n",
       "      <td>0.624798</td>\n",
       "      <td>-0.061310</td>\n",
       "      <td>0.909982</td>\n",
       "      <td>0.779079</td>\n",
       "      <td>0.623885</td>\n",
       "      <td>0.074145</td>\n",
       "      <td>0.935975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>0.764629</td>\n",
       "      <td>0.233614</td>\n",
       "      <td>0.062284</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>0.760537</td>\n",
       "      <td>0.223444</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>0.996719</td>\n",
       "      <td>0.757702</td>\n",
       "      <td>0.222465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130770</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.722036</td>\n",
       "      <td>0.652205</td>\n",
       "      <td>0.124014</td>\n",
       "      <td>0.686260</td>\n",
       "      <td>0.828936</td>\n",
       "      <td>0.623464</td>\n",
       "      <td>0.090504</td>\n",
       "      <td>0.776909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17048</th>\n",
       "      <td>0.425535</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.142120</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.420551</td>\n",
       "      <td>0.195677</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>0.416386</td>\n",
       "      <td>0.195740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114559</td>\n",
       "      <td>0.933055</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>0.789676</td>\n",
       "      <td>0.242446</td>\n",
       "      <td>0.931645</td>\n",
       "      <td>0.430837</td>\n",
       "      <td>0.813580</td>\n",
       "      <td>0.052207</td>\n",
       "      <td>0.914203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>0.330460</td>\n",
       "      <td>0.419674</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.328011</td>\n",
       "      <td>0.406505</td>\n",
       "      <td>-0.112793</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.327059</td>\n",
       "      <td>0.405736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081496</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.414087</td>\n",
       "      <td>0.844592</td>\n",
       "      <td>0.235085</td>\n",
       "      <td>0.936848</td>\n",
       "      <td>0.246513</td>\n",
       "      <td>0.889738</td>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.980218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13362 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        y1        z1        v1        x2        y2        z2  \\\n",
       "16392  0.423033  0.243220 -0.166562  0.998948  0.420859  0.225468 -0.153010   \n",
       "18350  0.577514  0.340552 -0.063475  0.999897  0.575350  0.325915 -0.050898   \n",
       "8905   0.413423  0.213392 -0.176539  0.999376  0.415025  0.205827 -0.165939   \n",
       "12233  0.452745  0.376188 -0.164070  0.999934  0.458794  0.366891 -0.163044   \n",
       "10623  0.428368  0.392361 -0.302119  0.999957  0.432887  0.381584 -0.284551   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "8222   0.419237  0.257569 -0.158076  0.999977  0.423303  0.238311 -0.178791   \n",
       "9449   0.788890  0.213552 -0.194469  0.999435  0.794791  0.203968 -0.188308   \n",
       "8471   0.764629  0.233614  0.062284  0.997778  0.760537  0.223444  0.052777   \n",
       "17048  0.425535  0.204700  0.142120  0.999793  0.420551  0.195677  0.108527   \n",
       "1318   0.330460  0.419674 -0.124680  0.999935  0.328011  0.406505 -0.112793   \n",
       "\n",
       "             v2        x3        y3  ...       z31       v31       x32  \\\n",
       "16392  0.998869  0.419460  0.223927  ...  0.167936  0.958910  0.489705   \n",
       "18350  0.999716  0.574365  0.325517  ...  0.102997  0.965358  0.522051   \n",
       "8905   0.999047  0.414906  0.206057  ...  0.135663  0.882528  0.416023   \n",
       "12233  0.999908  0.461115  0.367140  ...  0.055015  0.854127  0.499214   \n",
       "10623  0.999883  0.436236  0.381450  ...  0.117801  0.817713  0.445228   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "8222   0.999970  0.424627  0.237040  ...  0.413721  0.908600  0.493818   \n",
       "9449   0.999204  0.797630  0.203877  ...  0.139334  0.868544  0.782560   \n",
       "8471   0.996719  0.757702  0.222465  ...  0.130770  0.904020  0.722036   \n",
       "17048  0.999705  0.416386  0.195740  ...  0.114559  0.933055  0.387207   \n",
       "1318   0.999882  0.327059  0.405736  ...  0.081496  0.959361  0.414087   \n",
       "\n",
       "            y32       z32       v32       x33       y33       z33       v33  \n",
       "16392  0.776824  0.403006  0.926374  0.315292  0.808001  0.084077  0.977447  \n",
       "18350  0.889323  0.267132  0.940889  0.577008  0.892135  0.047235  0.984337  \n",
       "8905   0.569303  0.044649  0.839371  0.404568  0.559988  0.068812  0.828603  \n",
       "12233  0.766801  0.006070  0.977485  0.375258  0.758957 -0.023410  0.934828  \n",
       "10623  0.858981  0.289428  0.953463  0.411308  0.919083 -0.001454  0.975376  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "8222   0.851053  0.039051  0.990450  0.318970  0.791333  0.361413  0.952832  \n",
       "9449   0.624798 -0.061310  0.909982  0.779079  0.623885  0.074145  0.935975  \n",
       "8471   0.652205  0.124014  0.686260  0.828936  0.623464  0.090504  0.776909  \n",
       "17048  0.789676  0.242446  0.931645  0.430837  0.813580  0.052207  0.914203  \n",
       "1318   0.844592  0.235085  0.936848  0.246513  0.889738  0.014764  0.980218  \n",
       "\n",
       "[13362 rows x 132 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16392    zjg\n",
       "18350    zyf\n",
       "8905     syj\n",
       "12233    xch\n",
       "10623     wq\n",
       "        ... \n",
       "8222     syj\n",
       "9449      wl\n",
       "8471     syj\n",
       "17048    zjg\n",
       "1318      hy\n",
       "Name: Class, Length: 13362, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Measuring Accuracy\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, plot_roc_curve\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Data processing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Save and load models\n",
    "import pickle\n",
    "\n",
    "# Managing Datasets\n",
    "import pandas as pd\n",
    "# Extra Graphs\n",
    "import seaborn as sns\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise the model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Train the model on the training data and the training data survivors\n",
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9909202025493278\n"
     ]
    }
   ],
   "source": [
    "# Get a predicition from the test data\n",
    "pred = rfc.predict(x_test)\n",
    "\n",
    "# Generate an accuracy from the prediction\n",
    "rfc_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(rfc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.977987</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996885</td>\n",
       "      <td>0.996441</td>\n",
       "      <td>0.996337</td>\n",
       "      <td>0.995536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.989510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977695</td>\n",
       "      <td>0.996678</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.99092</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.990937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996491</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990712</td>\n",
       "      <td>0.996441</td>\n",
       "      <td>0.996337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.979239</td>\n",
       "      <td>0.989286</td>\n",
       "      <td>0.977695</td>\n",
       "      <td>0.996678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989399</td>\n",
       "      <td>0.99092</td>\n",
       "      <td>0.991055</td>\n",
       "      <td>0.990920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987826</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.974922</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.996441</td>\n",
       "      <td>0.996337</td>\n",
       "      <td>0.997763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.984348</td>\n",
       "      <td>0.994614</td>\n",
       "      <td>0.977695</td>\n",
       "      <td>0.996678</td>\n",
       "      <td>0.995902</td>\n",
       "      <td>0.984183</td>\n",
       "      <td>0.99092</td>\n",
       "      <td>0.990978</td>\n",
       "      <td>0.990916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.0</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.0</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.99092</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             fyc          hy         ljg         lqf         lsl     ml  \\\n",
       "precision    1.0    0.979310    0.990654    0.977987    0.993311    1.0   \n",
       "recall       1.0    0.996491    0.990654    0.971875    0.993311    1.0   \n",
       "f1-score     1.0    0.987826    0.990654    0.974922    0.993311    1.0   \n",
       "support    316.0  285.000000  321.000000  320.000000  299.000000  308.0   \n",
       "\n",
       "                  nhz          rj         syj          wl  ...         xxj  \\\n",
       "precision    0.996885    0.996441    0.996337    0.995536  ...    0.993377   \n",
       "recall       0.990712    0.996441    0.996337    1.000000  ...    0.993377   \n",
       "f1-score     0.993789    0.996441    0.996337    0.997763  ...    0.993377   \n",
       "support    323.000000  281.000000  273.000000  223.000000  ...  302.000000   \n",
       "\n",
       "                  yjf          zc         zdx         zjg          zl  \\\n",
       "precision    0.989510    1.000000    0.977695    0.996678    0.991837   \n",
       "recall       0.979239    0.989286    0.977695    0.996678    1.000000   \n",
       "f1-score     0.984348    0.994614    0.977695    0.996678    0.995902   \n",
       "support    289.000000  280.000000  269.000000  301.000000  243.000000   \n",
       "\n",
       "                  zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.979021   0.99092     0.990929      0.990937  \n",
       "recall       0.989399   0.99092     0.991055      0.990920  \n",
       "f1-score     0.984183   0.99092     0.990978      0.990916  \n",
       "support    283.000000   0.99092  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_classification = classification_report(y_test, pred, output_dict=True)\n",
    "pd.DataFrame(rfc_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huhon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise the model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model with the training data\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5049764274489261\n"
     ]
    }
   ],
   "source": [
    "# Get a predicition from the test data\n",
    "pred = lr.predict(x_test)\n",
    "\n",
    "# Generate an accuracy from the prediction\n",
    "lr_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.590618</td>\n",
       "      <td>0.348291</td>\n",
       "      <td>0.320872</td>\n",
       "      <td>0.402857</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.479070</td>\n",
       "      <td>0.629834</td>\n",
       "      <td>0.471053</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382838</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.615646</td>\n",
       "      <td>0.789286</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.504976</td>\n",
       "      <td>0.519176</td>\n",
       "      <td>0.514285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.876582</td>\n",
       "      <td>0.571930</td>\n",
       "      <td>0.320872</td>\n",
       "      <td>0.440625</td>\n",
       "      <td>0.170569</td>\n",
       "      <td>0.448052</td>\n",
       "      <td>0.637771</td>\n",
       "      <td>0.405694</td>\n",
       "      <td>0.655678</td>\n",
       "      <td>0.573991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>0.678201</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.226766</td>\n",
       "      <td>0.601329</td>\n",
       "      <td>0.909465</td>\n",
       "      <td>0.636042</td>\n",
       "      <td>0.504976</td>\n",
       "      <td>0.505655</td>\n",
       "      <td>0.504976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.705732</td>\n",
       "      <td>0.432935</td>\n",
       "      <td>0.320872</td>\n",
       "      <td>0.420896</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.547145</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.548239</td>\n",
       "      <td>0.602353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383471</td>\n",
       "      <td>0.564029</td>\n",
       "      <td>0.811538</td>\n",
       "      <td>0.346591</td>\n",
       "      <td>0.608403</td>\n",
       "      <td>0.845124</td>\n",
       "      <td>0.552995</td>\n",
       "      <td>0.504976</td>\n",
       "      <td>0.494848</td>\n",
       "      <td>0.492474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.504976</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl  \\\n",
       "precision    0.590618    0.348291    0.320872    0.402857    0.291429   \n",
       "recall       0.876582    0.571930    0.320872    0.440625    0.170569   \n",
       "f1-score     0.705732    0.432935    0.320872    0.420896    0.215190   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000   \n",
       "\n",
       "                   ml         nhz          rj         syj          wl  ...  \\\n",
       "precision    0.627273    0.479070    0.629834    0.471053    0.633663  ...   \n",
       "recall       0.448052    0.637771    0.405694    0.655678    0.573991  ...   \n",
       "f1-score     0.522727    0.547145    0.493506    0.548239    0.602353  ...   \n",
       "support    308.000000  323.000000  281.000000  273.000000  223.000000  ...   \n",
       "\n",
       "                  xxj         yjf          zc         zdx         zjg  \\\n",
       "precision    0.382838    0.482759    0.879167    0.734940    0.615646   \n",
       "recall       0.384106    0.678201    0.753571    0.226766    0.601329   \n",
       "f1-score     0.383471    0.564029    0.811538    0.346591    0.608403   \n",
       "support    302.000000  289.000000  280.000000  269.000000  301.000000   \n",
       "\n",
       "                   zl         zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.789286    0.489130  0.504976     0.519176      0.514285  \n",
       "recall       0.909465    0.636042  0.504976     0.505655      0.504976  \n",
       "f1-score     0.845124    0.552995  0.504976     0.494848      0.492474  \n",
       "support    243.000000  283.000000  0.504976  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_classification = classification_report(y_test, pred, output_dict=True)\n",
    "pd.DataFrame(lr_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit the model with the training data\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8697398288807403\n"
     ]
    }
   ],
   "source": [
    "# Get a prediction from the scaled test data\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "# Generate an accuracy score\n",
    "knn_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.943574</td>\n",
       "      <td>0.765896</td>\n",
       "      <td>0.824405</td>\n",
       "      <td>0.727513</td>\n",
       "      <td>0.806349</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.913313</td>\n",
       "      <td>0.903361</td>\n",
       "      <td>0.923636</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887273</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.924399</td>\n",
       "      <td>0.891775</td>\n",
       "      <td>0.975177</td>\n",
       "      <td>0.986175</td>\n",
       "      <td>0.950207</td>\n",
       "      <td>0.86974</td>\n",
       "      <td>0.876742</td>\n",
       "      <td>0.875174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.952532</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.862928</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.849498</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.913313</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.930403</td>\n",
       "      <td>0.946188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.875433</td>\n",
       "      <td>0.960714</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.913621</td>\n",
       "      <td>0.880658</td>\n",
       "      <td>0.809187</td>\n",
       "      <td>0.86974</td>\n",
       "      <td>0.868607</td>\n",
       "      <td>0.869740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.948031</td>\n",
       "      <td>0.839937</td>\n",
       "      <td>0.843227</td>\n",
       "      <td>0.787966</td>\n",
       "      <td>0.827362</td>\n",
       "      <td>0.923557</td>\n",
       "      <td>0.913313</td>\n",
       "      <td>0.828516</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.931567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845754</td>\n",
       "      <td>0.906810</td>\n",
       "      <td>0.942207</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.874046</td>\n",
       "      <td>0.86974</td>\n",
       "      <td>0.870358</td>\n",
       "      <td>0.870139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.86974</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl  \\\n",
       "precision    0.943574    0.765896    0.824405    0.727513    0.806349   \n",
       "recall       0.952532    0.929825    0.862928    0.859375    0.849498   \n",
       "f1-score     0.948031    0.839937    0.843227    0.787966    0.827362   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000   \n",
       "\n",
       "                   ml         nhz          rj         syj          wl  ...  \\\n",
       "precision    0.888889    0.913313    0.903361    0.923636    0.917391  ...   \n",
       "recall       0.961039    0.913313    0.765125    0.930403    0.946188  ...   \n",
       "f1-score     0.923557    0.913313    0.828516    0.927007    0.931567  ...   \n",
       "support    308.000000  323.000000  281.000000  273.000000  223.000000  ...   \n",
       "\n",
       "                  xxj         yjf          zc         zdx         zjg  \\\n",
       "precision    0.887273    0.940520    0.924399    0.891775    0.975177   \n",
       "recall       0.807947    0.875433    0.960714    0.765799    0.913621   \n",
       "f1-score     0.845754    0.906810    0.942207    0.824000    0.943396   \n",
       "support    302.000000  289.000000  280.000000  269.000000  301.000000   \n",
       "\n",
       "                   zl         zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.986175    0.950207   0.86974     0.876742      0.875174  \n",
       "recall       0.880658    0.809187   0.86974     0.868607      0.869740  \n",
       "f1-score     0.930435    0.874046   0.86974     0.870358      0.870139  \n",
       "support    243.000000  283.000000   0.86974  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classification = classification_report(y_test, pred, output_dict=True)\n",
    "pd.DataFrame(knn_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise model\n",
    "svc = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49781735638204994\n"
     ]
    }
   ],
   "source": [
    "# Get a prediction from the scaled test data\n",
    "pred = svc.predict(x_test)\n",
    "\n",
    "# Generate an accuracy score\n",
    "svc_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(svc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.691906</td>\n",
       "      <td>0.354023</td>\n",
       "      <td>0.317380</td>\n",
       "      <td>0.291280</td>\n",
       "      <td>0.355072</td>\n",
       "      <td>0.823755</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341598</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.497817</td>\n",
       "      <td>0.555212</td>\n",
       "      <td>0.545929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.838608</td>\n",
       "      <td>0.540351</td>\n",
       "      <td>0.392523</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>0.163880</td>\n",
       "      <td>0.698052</td>\n",
       "      <td>0.557276</td>\n",
       "      <td>0.188612</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.573991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410596</td>\n",
       "      <td>0.494810</td>\n",
       "      <td>0.796429</td>\n",
       "      <td>0.185874</td>\n",
       "      <td>0.624585</td>\n",
       "      <td>0.831276</td>\n",
       "      <td>0.540636</td>\n",
       "      <td>0.497817</td>\n",
       "      <td>0.495293</td>\n",
       "      <td>0.497817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.758226</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>0.350975</td>\n",
       "      <td>0.365541</td>\n",
       "      <td>0.224256</td>\n",
       "      <td>0.755712</td>\n",
       "      <td>0.457433</td>\n",
       "      <td>0.298592</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.697548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372932</td>\n",
       "      <td>0.520947</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.280112</td>\n",
       "      <td>0.738703</td>\n",
       "      <td>0.809619</td>\n",
       "      <td>0.506623</td>\n",
       "      <td>0.497817</td>\n",
       "      <td>0.487041</td>\n",
       "      <td>0.486378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.497817</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl  \\\n",
       "precision    0.691906    0.354023    0.317380    0.291280    0.355072   \n",
       "recall       0.838608    0.540351    0.392523    0.490625    0.163880   \n",
       "f1-score     0.758226    0.427778    0.350975    0.365541    0.224256   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000   \n",
       "\n",
       "                   ml         nhz          rj         syj          wl  ...  \\\n",
       "precision    0.823755    0.387931    0.716216    0.466667    0.888889  ...   \n",
       "recall       0.698052    0.557276    0.188612    0.846154    0.573991  ...   \n",
       "f1-score     0.755712    0.457433    0.298592    0.601562    0.697548  ...   \n",
       "support    308.000000  323.000000  281.000000  273.000000  223.000000  ...   \n",
       "\n",
       "                  xxj         yjf          zc         zdx         zjg  \\\n",
       "precision    0.341598    0.550000    0.844697    0.568182    0.903846   \n",
       "recall       0.410596    0.494810    0.796429    0.185874    0.624585   \n",
       "f1-score     0.372932    0.520947    0.819853    0.280112    0.738703   \n",
       "support    302.000000  289.000000  280.000000  269.000000  301.000000   \n",
       "\n",
       "                   zl         zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.789062    0.476636  0.497817     0.555212      0.545929  \n",
       "recall       0.831276    0.540636  0.497817     0.495293      0.497817  \n",
       "f1-score     0.809619    0.506623  0.497817     0.487041      0.486378  \n",
       "support    243.000000  283.000000  0.497817  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_classification = classification_report(y_test, pred, output_dict=True)\n",
    "pd.DataFrame(svc_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's easy to find that the performance are not good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this case, we decided to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve accuracy with Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'knn':make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
    "    'dt':make_pipeline(StandardScaler(), DecisionTreeClassifier()),\n",
    "    'svc':make_pipeline(StandardScaler(),SVC())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lr', 'rc', 'rf', 'gb', 'knn', 'dt', 'svc'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huhon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(x_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('logisticregression',\n",
       "                  LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=100,\n",
       "                                     multi_class='auto', n_jobs=None,\n",
       "                                     penalty='l2', random_state=None,\n",
       "                                     solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'rc': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('ridgeclassifier',\n",
       "                  RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,\n",
       "                                  fit_intercept=True, max_iter=None,\n",
       "                                  normalize=False, random_state=None,\n",
       "                                  solver='auto', tol=0.001))],\n",
       "          verbose=False),\n",
       " 'rf': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('randomforestclassifier',\n",
       "                  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                         class_weight=None, criterion='gini',\n",
       "                                         max_depth=None, max_features='auto',\n",
       "                                         max_leaf_nodes=None, max_samples=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=100, n_jobs=None,\n",
       "                                         oob_score=False, random_state=None,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'gb': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('gradientboostingclassifier',\n",
       "                  GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                             criterion='friedman_mse', init=None,\n",
       "                                             learning_rate=0.1, loss='deviance',\n",
       "                                             max_depth=3, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100,\n",
       "                                             n_iter_no_change=None,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=None, subsample=1.0,\n",
       "                                             tol=0.0001, validation_fraction=0.1,\n",
       "                                             verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'knn': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('kneighborsclassifier',\n",
       "                  KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                       metric='minkowski', metric_params=None,\n",
       "                                       n_jobs=None, n_neighbors=5, p=2,\n",
       "                                       weights='uniform'))],\n",
       "          verbose=False),\n",
       " 'dt': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('decisiontreeclassifier',\n",
       "                  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                         criterion='gini', max_depth=None,\n",
       "                                         max_features=None, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         presort='deprecated', random_state=None,\n",
       "                                         splitter='best'))],\n",
       "          verbose=False),\n",
       " 'svc': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('svc',\n",
       "                  SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                      coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                      gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                      probability=False, random_state=None, shrinking=True,\n",
       "                      tol=0.001, verbose=False))],\n",
       "          verbose=False)}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr : 0.8700890518596124\n",
      "rc : 0.7178278330714161\n",
      "rf : 0.9924917059542517\n",
      "gb : 0.9533787323205867\n",
      "knn : 0.9249170595425179\n",
      "dt : 0.8945346603806531\n",
      "svc : 0.9158372620918457\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(x_test)\n",
    "    print(algo,':', accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- obviously, the results are better than without normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Serialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8700890518596124\n"
     ]
    }
   ],
   "source": [
    "pred = fit_models['lr'].predict(x_test)\n",
    "\n",
    "lr_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[307   3   0   0   0   0   2   2   0   0   0   0   0   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0 253   0   0   4   0   0   9   0   0   5   0   1  13   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3 209   1  24   0  19   0   0   0  14  24  27   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1 254   0   0   0   0   0   0   0   8   1   0  22   0  19   0\n",
      "    0  15]\n",
      " [  0   5  26   0 200   0  15   0   0   0   6   4  28  14   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 290   0   0  12   0   0   0   0   0   0   0   3   3\n",
      "    0   0]\n",
      " [  0   0  16   0  13   0 283   0   0   0   6   2   1   1   0   0   1   0\n",
      "    0   0]\n",
      " [  1   2   0   0   1   0   0 269   0   0   0   0   0   8   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   0 264   2   0   0   0   0   1   0   1   4\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   3 216   0   0   0   0   0   2   0   2\n",
      "    0   0]\n",
      " [  0  12   9   0   8   0   4   0   0   0 249   8   9   9   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  20   5   3   0   5   0   0   0   6 222   1   0   0   0   0   0\n",
      "    0   2]\n",
      " [  0   8  11   1  12   0   4   0   0   0   9   3 191   0   0   0   0   0\n",
      "    0   0]\n",
      " [  6   8   1   0  10   0   0   5   0   0   2   0   0 270   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   8   0   0   0   0   0   0   0   0   0   0 272   0   8   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0 269   0   0\n",
      "   10   0]\n",
      " [  0   0   0  32   0   3   0   0   0   0   0   2   0   0  16   0 208   0\n",
      "    0   8]\n",
      " [  0   0   0   0   0  19   0   0   6   3   0   0   0   0   0   0   1 272\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0\n",
      "  234   0]\n",
      " [  0   0   0  10   0   1   3   0   0   0   0   1   0   1   0   0  16   0\n",
      "    0 251]]\n"
     ]
    }
   ],
   "source": [
    "lr_confusion = confusion_matrix(y_test, pred)\n",
    "print(lr_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fyc': {'precision': 0.9777070063694268, 'recall': 0.9715189873417721, 'f1-score': 0.9746031746031746, 'support': 316}, 'hy': {'precision': 0.8605442176870748, 'recall': 0.887719298245614, 'f1-score': 0.8739205526770294, 'support': 285}, 'ljg': {'precision': 0.7133105802047781, 'recall': 0.6510903426791277, 'f1-score': 0.6807817589576547, 'support': 321}, 'lqf': {'precision': 0.8167202572347267, 'recall': 0.79375, 'f1-score': 0.8050713153724247, 'support': 320}, 'lsl': {'precision': 0.7272727272727273, 'recall': 0.6688963210702341, 'f1-score': 0.6968641114982579, 'support': 299}, 'ml': {'precision': 0.9235668789808917, 'recall': 0.9415584415584416, 'f1-score': 0.9324758842443731, 'support': 308}, 'nhz': {'precision': 0.844776119402985, 'recall': 0.8761609907120743, 'f1-score': 0.8601823708206686, 'support': 323}, 'rj': {'precision': 0.9438596491228071, 'recall': 0.9572953736654805, 'f1-score': 0.9505300353356891, 'support': 281}, 'syj': {'precision': 0.9263157894736842, 'recall': 0.967032967032967, 'f1-score': 0.946236559139785, 'support': 273}, 'wl': {'precision': 0.972972972972973, 'recall': 0.968609865470852, 'f1-score': 0.9707865168539327, 'support': 223}, 'wq': {'precision': 0.8383838383838383, 'recall': 0.8084415584415584, 'f1-score': 0.8231404958677685, 'support': 308}, 'wyc': {'precision': 0.8102189781021898, 'recall': 0.8409090909090909, 'f1-score': 0.825278810408922, 'support': 264}, 'xch': {'precision': 0.7374517374517374, 'recall': 0.799163179916318, 'f1-score': 0.7670682730923695, 'support': 239}, 'xxj': {'precision': 0.8490566037735849, 'recall': 0.8940397350993378, 'f1-score': 0.870967741935484, 'support': 302}, 'yjf': {'precision': 0.8717948717948718, 'recall': 0.9411764705882353, 'f1-score': 0.9051580698835274, 'support': 289}, 'zc': {'precision': 0.9607142857142857, 'recall': 0.9607142857142857, 'f1-score': 0.9607142857142859, 'support': 280}, 'zdx': {'precision': 0.8093385214007782, 'recall': 0.7732342007434945, 'f1-score': 0.7908745247148289, 'support': 269}, 'zjg': {'precision': 0.9679715302491103, 'recall': 0.9036544850498339, 'f1-score': 0.9347079037800687, 'support': 301}, 'zl': {'precision': 0.9590163934426229, 'recall': 0.9629629629629629, 'f1-score': 0.9609856262833675, 'support': 243}, 'zyf': {'precision': 0.9061371841155235, 'recall': 0.8869257950530035, 'f1-score': 0.8964285714285714, 'support': 283}, 'accuracy': 0.8700890518596124, 'macro avg': {'precision': 0.8708565071575309, 'recall': 0.8727427176127343, 'f1-score': 0.8713388291306092, 'support': 5727}, 'weighted avg': {'precision': 0.8693339234884881, 'recall': 0.8700890518596124, 'f1-score': 0.8692440619552597, 'support': 5727}}\n"
     ]
    }
   ],
   "source": [
    "lr_classification = classification_report(y_test, pred, output_dict=True)\n",
    "print(lr_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.977707</td>\n",
       "      <td>0.860544</td>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.844776</td>\n",
       "      <td>0.943860</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.960714</td>\n",
       "      <td>0.809339</td>\n",
       "      <td>0.967972</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.906137</td>\n",
       "      <td>0.870089</td>\n",
       "      <td>0.870857</td>\n",
       "      <td>0.869334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.971519</td>\n",
       "      <td>0.887719</td>\n",
       "      <td>0.651090</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.668896</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>0.876161</td>\n",
       "      <td>0.957295</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.968610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.960714</td>\n",
       "      <td>0.773234</td>\n",
       "      <td>0.903654</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.886926</td>\n",
       "      <td>0.870089</td>\n",
       "      <td>0.872743</td>\n",
       "      <td>0.870089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.873921</td>\n",
       "      <td>0.680782</td>\n",
       "      <td>0.805071</td>\n",
       "      <td>0.696864</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.860182</td>\n",
       "      <td>0.950530</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.905158</td>\n",
       "      <td>0.960714</td>\n",
       "      <td>0.790875</td>\n",
       "      <td>0.934708</td>\n",
       "      <td>0.960986</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.870089</td>\n",
       "      <td>0.871339</td>\n",
       "      <td>0.869244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.870089</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl  \\\n",
       "precision    0.977707    0.860544    0.713311    0.816720    0.727273   \n",
       "recall       0.971519    0.887719    0.651090    0.793750    0.668896   \n",
       "f1-score     0.974603    0.873921    0.680782    0.805071    0.696864   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000   \n",
       "\n",
       "                   ml         nhz          rj         syj          wl  ...  \\\n",
       "precision    0.923567    0.844776    0.943860    0.926316    0.972973  ...   \n",
       "recall       0.941558    0.876161    0.957295    0.967033    0.968610  ...   \n",
       "f1-score     0.932476    0.860182    0.950530    0.946237    0.970787  ...   \n",
       "support    308.000000  323.000000  281.000000  273.000000  223.000000  ...   \n",
       "\n",
       "                  xxj         yjf          zc         zdx         zjg  \\\n",
       "precision    0.849057    0.871795    0.960714    0.809339    0.967972   \n",
       "recall       0.894040    0.941176    0.960714    0.773234    0.903654   \n",
       "f1-score     0.870968    0.905158    0.960714    0.790875    0.934708   \n",
       "support    302.000000  289.000000  280.000000  269.000000  301.000000   \n",
       "\n",
       "                   zl         zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.959016    0.906137  0.870089     0.870857      0.869334  \n",
       "recall       0.962963    0.886926  0.870089     0.872743      0.870089  \n",
       "f1-score     0.960986    0.896429  0.870089     0.871339      0.869244  \n",
       "support    243.000000  283.000000  0.870089  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lr_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7178278330714161\n"
     ]
    }
   ],
   "source": [
    "pred = fit_models['rc'].predict(x_test)\n",
    "\n",
    "rc_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(rc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[302   0   0   0   0   0   4   0   0   0   0   0   0   8   0   0   0   2\n",
      "    0   0]\n",
      " [ 20 192   4   9   0   1   0   5   0   1  10  18   4  10  11   0   0   0\n",
      "    0   0]\n",
      " [ 17  10 160   4  12   2  30  10   7   0   3  23  18   6   6   0   2   3\n",
      "    0   8]\n",
      " [  7  24   1 181   3   3   1   1   5  18  16   3   7  10  21   2   9   3\n",
      "    1   4]\n",
      " [ 20   7  13   0 140   4  30  12  10   1   3   6  11  24   3   0   1   3\n",
      "    0  11]\n",
      " [  0   0   0   1   0 223   2   0  25  21   3   0   0   0   0   1   0  14\n",
      "   12   6]\n",
      " [  6   0   2   0   2   2 278   4   2   4   3   1   0   3   2   0   0   5\n",
      "    0   9]\n",
      " [  6  14   9   2   2   1  13 171  14   0   2  15  12   6   6   0   1   0\n",
      "    0   7]\n",
      " [  0   0   0   0   0   1   0   0 264   0   0   0   0   0   0   3   0   1\n",
      "    4   0]\n",
      " [  0   0   1   0   0   3   0   0   3 192   0   0   0   0   1   4   0   0\n",
      "   19   0]\n",
      " [  3  26   3  10  10   5   5   2   2   0 197   1  12  15  14   0   1   0\n",
      "    0   2]\n",
      " [ 19   7  12   5   4   3   8  10   8   0   3 161   2   3  10   0   0   2\n",
      "    0   7]\n",
      " [  0  21   6  10   5   4   0   8  10   0  20   4 132   5   0   0   0   6\n",
      "    0   8]\n",
      " [ 11   7   2   4   0   1   5  11   0   0   5   0   1 251   1   0   1   0\n",
      "    0   2]\n",
      " [  0   2   1  13   0   0   0   2   1   1   1   1   3   1 255   1   2   1\n",
      "    1   3]\n",
      " [  3   0   0   0   0   2   0   0  10   8   0   0   0   0   0 236   0   4\n",
      "   17   0]\n",
      " [ 20  15   4  23   4   8   4   4  12   5  13   4   5  10  17   5  96   1\n",
      "    3  16]\n",
      " [  8   0   1   0   0  21   1   0  16   1   1   0   0   2   0  23   0 222\n",
      "    5   0]\n",
      " [  0   0   0   0   0   0   0   0   0   7   0   0   0   0   0   3   0   3\n",
      "  230   0]\n",
      " [  3   0   0   0   0   3  16   1   4  10   9   1   1   4   1   1   1   0\n",
      "    0 228]]\n"
     ]
    }
   ],
   "source": [
    "rc_confusion = confusion_matrix(y_test, pred)\n",
    "print(rc_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fyc': {'precision': 0.6786516853932584, 'recall': 0.9556962025316456, 'f1-score': 0.7936925098554534, 'support': 316}, 'hy': {'precision': 0.5907692307692308, 'recall': 0.6736842105263158, 'f1-score': 0.6295081967213115, 'support': 285}, 'ljg': {'precision': 0.730593607305936, 'recall': 0.4984423676012461, 'f1-score': 0.5925925925925926, 'support': 321}, 'lqf': {'precision': 0.6908396946564885, 'recall': 0.565625, 'f1-score': 0.6219931271477663, 'support': 320}, 'lsl': {'precision': 0.7692307692307693, 'recall': 0.4682274247491639, 'f1-score': 0.5821205821205822, 'support': 299}, 'ml': {'precision': 0.7770034843205574, 'recall': 0.724025974025974, 'f1-score': 0.7495798319327732, 'support': 308}, 'nhz': {'precision': 0.7002518891687658, 'recall': 0.8606811145510835, 'f1-score': 0.7722222222222224, 'support': 323}, 'rj': {'precision': 0.7095435684647303, 'recall': 0.608540925266904, 'f1-score': 0.6551724137931035, 'support': 281}, 'syj': {'precision': 0.6717557251908397, 'recall': 0.967032967032967, 'f1-score': 0.7927927927927928, 'support': 273}, 'wl': {'precision': 0.7137546468401487, 'recall': 0.8609865470852018, 'f1-score': 0.7804878048780489, 'support': 223}, 'wq': {'precision': 0.6816608996539792, 'recall': 0.6396103896103896, 'f1-score': 0.6599664991624791, 'support': 308}, 'wyc': {'precision': 0.6764705882352942, 'recall': 0.6098484848484849, 'f1-score': 0.6414342629482073, 'support': 264}, 'xch': {'precision': 0.6346153846153846, 'recall': 0.5523012552301255, 'f1-score': 0.5906040268456376, 'support': 239}, 'xxj': {'precision': 0.7011173184357542, 'recall': 0.8311258278145696, 'f1-score': 0.7606060606060606, 'support': 302}, 'yjf': {'precision': 0.7327586206896551, 'recall': 0.8823529411764706, 'f1-score': 0.8006279434850861, 'support': 289}, 'zc': {'precision': 0.8458781362007168, 'recall': 0.8428571428571429, 'f1-score': 0.8443649373881931, 'support': 280}, 'zdx': {'precision': 0.8421052631578947, 'recall': 0.35687732342007433, 'f1-score': 0.5013054830287206, 'support': 269}, 'zjg': {'precision': 0.8222222222222222, 'recall': 0.7375415282392026, 'f1-score': 0.7775831873905429, 'support': 301}, 'zl': {'precision': 0.7876712328767124, 'recall': 0.9465020576131687, 'f1-score': 0.8598130841121495, 'support': 243}, 'zyf': {'precision': 0.7331189710610932, 'recall': 0.8056537102473498, 'f1-score': 0.7676767676767677, 'support': 283}, 'accuracy': 0.7178278330714161, 'macro avg': {'precision': 0.7245006469244716, 'recall': 0.7193806697213739, 'f1-score': 0.7087072163350245, 'support': 5727}, 'weighted avg': {'precision': 0.7245162547570262, 'recall': 0.7178278330714161, 'f1-score': 0.7080101222977263, 'support': 5727}}\n"
     ]
    }
   ],
   "source": [
    "rc_classification = classification_report(y_test, pred, output_dict=True)\n",
    "print(rc_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.678652</td>\n",
       "      <td>0.590769</td>\n",
       "      <td>0.730594</td>\n",
       "      <td>0.690840</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.777003</td>\n",
       "      <td>0.700252</td>\n",
       "      <td>0.709544</td>\n",
       "      <td>0.671756</td>\n",
       "      <td>0.713755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701117</td>\n",
       "      <td>0.732759</td>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.787671</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>0.717828</td>\n",
       "      <td>0.724501</td>\n",
       "      <td>0.724516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.955696</td>\n",
       "      <td>0.673684</td>\n",
       "      <td>0.498442</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>0.468227</td>\n",
       "      <td>0.724026</td>\n",
       "      <td>0.860681</td>\n",
       "      <td>0.608541</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.860987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831126</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.356877</td>\n",
       "      <td>0.737542</td>\n",
       "      <td>0.946502</td>\n",
       "      <td>0.805654</td>\n",
       "      <td>0.717828</td>\n",
       "      <td>0.719381</td>\n",
       "      <td>0.717828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.793693</td>\n",
       "      <td>0.629508</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.621993</td>\n",
       "      <td>0.582121</td>\n",
       "      <td>0.749580</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.792793</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760606</td>\n",
       "      <td>0.800628</td>\n",
       "      <td>0.844365</td>\n",
       "      <td>0.501305</td>\n",
       "      <td>0.777583</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.717828</td>\n",
       "      <td>0.708707</td>\n",
       "      <td>0.708010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.717828</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl  \\\n",
       "precision    0.678652    0.590769    0.730594    0.690840    0.769231   \n",
       "recall       0.955696    0.673684    0.498442    0.565625    0.468227   \n",
       "f1-score     0.793693    0.629508    0.592593    0.621993    0.582121   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000   \n",
       "\n",
       "                   ml         nhz          rj         syj          wl  ...  \\\n",
       "precision    0.777003    0.700252    0.709544    0.671756    0.713755  ...   \n",
       "recall       0.724026    0.860681    0.608541    0.967033    0.860987  ...   \n",
       "f1-score     0.749580    0.772222    0.655172    0.792793    0.780488  ...   \n",
       "support    308.000000  323.000000  281.000000  273.000000  223.000000  ...   \n",
       "\n",
       "                  xxj         yjf          zc         zdx         zjg  \\\n",
       "precision    0.701117    0.732759    0.845878    0.842105    0.822222   \n",
       "recall       0.831126    0.882353    0.842857    0.356877    0.737542   \n",
       "f1-score     0.760606    0.800628    0.844365    0.501305    0.777583   \n",
       "support    302.000000  289.000000  280.000000  269.000000  301.000000   \n",
       "\n",
       "                   zl         zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.787671    0.733119  0.717828     0.724501      0.724516  \n",
       "recall       0.946502    0.805654  0.717828     0.719381      0.717828  \n",
       "f1-score     0.859813    0.767677  0.717828     0.708707      0.708010  \n",
       "support    243.000000  283.000000  0.717828  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rc_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924917059542517\n"
     ]
    }
   ],
   "source": [
    "pred = fit_models['rf'].predict(x_test)\n",
    "\n",
    "rf_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[316   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0 283   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0 317   0   0   0   1   0   0   0   1   2   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0 318   0   0   0   0   0   0   0   1   0   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0   0 297   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 308   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0 323   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0 280   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0 271   2   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 223   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1   0   0   0   0   0   0   0 304   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 264   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   1   0   0   0   0   0   3   0 234   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   0 300   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   3   0   0   0   0   0   0   0   0   0   0 286   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 276   0   1\n",
      "    3   0]\n",
      " [  0   0   0   2   0   0   0   0   0   0   0   0   0   0   2   0 263   0\n",
      "    0   2]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0 299\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  243   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0\n",
      "    0 279]]\n"
     ]
    }
   ],
   "source": [
    "rf_confusion = confusion_matrix(y_test, pred)\n",
    "print(rf_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fyc': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 316}, 'hy': {'precision': 0.9826388888888888, 'recall': 0.9929824561403509, 'f1-score': 0.987783595113438, 'support': 285}, 'ljg': {'precision': 0.9937304075235109, 'recall': 0.9875389408099688, 'f1-score': 0.990625, 'support': 321}, 'lqf': {'precision': 0.9845201238390093, 'recall': 0.99375, 'f1-score': 0.9891135303265941, 'support': 320}, 'lsl': {'precision': 0.9966442953020134, 'recall': 0.9933110367892977, 'f1-score': 0.9949748743718593, 'support': 299}, 'ml': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 308}, 'nhz': {'precision': 0.9969135802469136, 'recall': 1.0, 'f1-score': 0.9984544049459042, 'support': 323}, 'rj': {'precision': 0.99644128113879, 'recall': 0.99644128113879, 'f1-score': 0.99644128113879, 'support': 281}, 'syj': {'precision': 0.9926739926739927, 'recall': 0.9926739926739927, 'f1-score': 0.9926739926739927, 'support': 273}, 'wl': {'precision': 0.9911111111111112, 'recall': 1.0, 'f1-score': 0.9955357142857144, 'support': 223}, 'wq': {'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1-score': 0.987012987012987, 'support': 308}, 'wyc': {'precision': 0.9887640449438202, 'recall': 1.0, 'f1-score': 0.9943502824858756, 'support': 264}, 'xch': {'precision': 0.9915254237288136, 'recall': 0.9790794979079498, 'f1-score': 0.9852631578947368, 'support': 239}, 'xxj': {'precision': 0.9933774834437086, 'recall': 0.9933774834437086, 'f1-score': 0.9933774834437086, 'support': 302}, 'yjf': {'precision': 0.9930555555555556, 'recall': 0.9896193771626297, 'f1-score': 0.9913344887348354, 'support': 289}, 'zc': {'precision': 1.0, 'recall': 0.9857142857142858, 'f1-score': 0.9928057553956835, 'support': 280}, 'zdx': {'precision': 0.9813432835820896, 'recall': 0.9776951672862454, 'f1-score': 0.9795158286778398, 'support': 269}, 'zjg': {'precision': 0.9966666666666667, 'recall': 0.9933554817275747, 'f1-score': 0.995008319467554, 'support': 301}, 'zl': {'precision': 0.9878048780487805, 'recall': 1.0, 'f1-score': 0.9938650306748467, 'support': 243}, 'zyf': {'precision': 0.9928825622775801, 'recall': 0.9858657243816255, 'f1-score': 0.9893617021276595, 'support': 283}, 'accuracy': 0.9924917059542517, 'macro avg': {'precision': 0.9923553282992115, 'recall': 0.9924208856094705, 'f1-score': 0.9923748714386009, 'support': 5727}, 'weighted avg': {'precision': 0.9925100737562886, 'recall': 0.9924917059542517, 'f1-score': 0.992488471823071, 'support': 5727}}\n"
     ]
    }
   ],
   "source": [
    "rf_classification = classification_report(y_test, pred, output_dict=True)\n",
    "print(rf_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982639</td>\n",
       "      <td>0.993730</td>\n",
       "      <td>0.984520</td>\n",
       "      <td>0.996644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.996441</td>\n",
       "      <td>0.992674</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981343</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.992883</td>\n",
       "      <td>0.992492</td>\n",
       "      <td>0.992355</td>\n",
       "      <td>0.992510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992982</td>\n",
       "      <td>0.987539</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996441</td>\n",
       "      <td>0.992674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.989619</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.977695</td>\n",
       "      <td>0.993355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>0.992492</td>\n",
       "      <td>0.992421</td>\n",
       "      <td>0.992492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987784</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.989114</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998454</td>\n",
       "      <td>0.996441</td>\n",
       "      <td>0.992674</td>\n",
       "      <td>0.995536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.991334</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.979516</td>\n",
       "      <td>0.995008</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.992492</td>\n",
       "      <td>0.992375</td>\n",
       "      <td>0.992488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.0</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.0</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.992492</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             fyc          hy         ljg         lqf         lsl     ml  \\\n",
       "precision    1.0    0.982639    0.993730    0.984520    0.996644    1.0   \n",
       "recall       1.0    0.992982    0.987539    0.993750    0.993311    1.0   \n",
       "f1-score     1.0    0.987784    0.990625    0.989114    0.994975    1.0   \n",
       "support    316.0  285.000000  321.000000  320.000000  299.000000  308.0   \n",
       "\n",
       "                  nhz          rj         syj          wl  ...         xxj  \\\n",
       "precision    0.996914    0.996441    0.992674    0.991111  ...    0.993377   \n",
       "recall       1.000000    0.996441    0.992674    1.000000  ...    0.993377   \n",
       "f1-score     0.998454    0.996441    0.992674    0.995536  ...    0.993377   \n",
       "support    323.000000  281.000000  273.000000  223.000000  ...  302.000000   \n",
       "\n",
       "                  yjf          zc         zdx         zjg          zl  \\\n",
       "precision    0.993056    1.000000    0.981343    0.996667    0.987805   \n",
       "recall       0.989619    0.985714    0.977695    0.993355    1.000000   \n",
       "f1-score     0.991334    0.992806    0.979516    0.995008    0.993865   \n",
       "support    289.000000  280.000000  269.000000  301.000000  243.000000   \n",
       "\n",
       "                  zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.992883  0.992492     0.992355      0.992510  \n",
       "recall       0.985866  0.992492     0.992421      0.992492  \n",
       "f1-score     0.989362  0.992492     0.992375      0.992488  \n",
       "support    283.000000  0.992492  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533787323205867\n"
     ]
    }
   ],
   "source": [
    "pred = fit_models['gb'].predict(x_test)\n",
    "\n",
    "gb_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(gb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[309   0   0   0   0   0   0   6   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0 282   0   0   0   0   0   2   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2 293   0   8   0   7   0   0   0   0  10   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0 295   0   0   2   0   0   0   0   8   0   0   5   0   9   0\n",
      "    0   1]\n",
      " [  0   4   1   0 282   0   1   0   0   0   2   0   6   3   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 308   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   8   0   4   0 308   0   0   0   2   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  12   0   0   0   0   0 258   0   0   0   0   0   7   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0 269   3   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1 222   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8   4   0   5   0   2   0   0   0 280   2   7   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   9   3   1   0   2   0   0   0   0 248   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   4   0   6   0   1   0   0   0   8   0 217   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   5   0   0   3   0   0   1   0   0   1   0   0 292   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  11   0   0   0   0   0   0   0   1   0   0 271   0   4   0\n",
      "    0   2]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0 277   0   1\n",
      "    1   0]\n",
      " [  0   0   0  11   0   0   0   0   0   0   0   0   0   0   5   0 247   0\n",
      "    0   6]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0 300\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0   0\n",
      "  237   0]\n",
      " [  0   0   1   7   0   0   1   0   0   0   0   0   0   0   2   0   7   0\n",
      "    0 265]]\n"
     ]
    }
   ],
   "source": [
    "gb_confusion = confusion_matrix(y_test, pred)\n",
    "print(gb_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fyc': {'precision': 0.987220447284345, 'recall': 0.9778481012658228, 'f1-score': 0.9825119236883942, 'support': 316}, 'hy': {'precision': 0.889589905362776, 'recall': 0.9894736842105263, 'f1-score': 0.93687707641196, 'support': 285}, 'ljg': {'precision': 0.915625, 'recall': 0.9127725856697819, 'f1-score': 0.9141965678627145, 'support': 321}, 'lqf': {'precision': 0.9021406727828746, 'recall': 0.921875, 'f1-score': 0.9119010819165378, 'support': 320}, 'lsl': {'precision': 0.912621359223301, 'recall': 0.9431438127090301, 'f1-score': 0.9276315789473685, 'support': 299}, 'ml': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 308}, 'nhz': {'precision': 0.9506172839506173, 'recall': 0.9535603715170279, 'f1-score': 0.9520865533230293, 'support': 323}, 'rj': {'precision': 0.9662921348314607, 'recall': 0.9181494661921709, 'f1-score': 0.9416058394160584, 'support': 281}, 'syj': {'precision': 0.992619926199262, 'recall': 0.9853479853479854, 'f1-score': 0.988970588235294, 'support': 273}, 'wl': {'precision': 0.9823008849557522, 'recall': 0.9955156950672646, 'f1-score': 0.9888641425389755, 'support': 223}, 'wq': {'precision': 0.9556313993174061, 'recall': 0.9090909090909091, 'f1-score': 0.9317803660565723, 'support': 308}, 'wyc': {'precision': 0.9219330855018587, 'recall': 0.9393939393939394, 'f1-score': 0.9305816135084429, 'support': 264}, 'xch': {'precision': 0.9353448275862069, 'recall': 0.9079497907949791, 'f1-score': 0.9214437367303608, 'support': 239}, 'xxj': {'precision': 0.9605263157894737, 'recall': 0.9668874172185431, 'f1-score': 0.9636963696369637, 'support': 302}, 'yjf': {'precision': 0.9575971731448764, 'recall': 0.9377162629757786, 'f1-score': 0.9475524475524476, 'support': 289}, 'zc': {'precision': 0.9787985865724381, 'recall': 0.9892857142857143, 'f1-score': 0.9840142095914743, 'support': 280}, 'zdx': {'precision': 0.9250936329588015, 'recall': 0.9182156133828996, 'f1-score': 0.9216417910447762, 'support': 269}, 'zjg': {'precision': 0.9933774834437086, 'recall': 0.9966777408637874, 'f1-score': 0.9950248756218905, 'support': 301}, 'zl': {'precision': 0.9957983193277311, 'recall': 0.9753086419753086, 'f1-score': 0.9854469854469856, 'support': 243}, 'zyf': {'precision': 0.9671532846715328, 'recall': 0.9363957597173145, 'f1-score': 0.9515260323159785, 'support': 283}, 'accuracy': 0.9533787323205867, 'macro avg': {'precision': 0.954514086145221, 'recall': 0.9537304245839392, 'f1-score': 0.9538676889923112, 'support': 5727}, 'weighted avg': {'precision': 0.9539524281148659, 'recall': 0.9533787323205867, 'f1-score': 0.9534121527239778, 'support': 5727}}\n"
     ]
    }
   ],
   "source": [
    "gb_classification = classification_report(y_test, pred, output_dict=True)\n",
    "print(gb_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.987220</td>\n",
       "      <td>0.889590</td>\n",
       "      <td>0.915625</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.992620</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.957597</td>\n",
       "      <td>0.978799</td>\n",
       "      <td>0.925094</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.995798</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.953379</td>\n",
       "      <td>0.954514</td>\n",
       "      <td>0.953952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.977848</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.912773</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.943144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953560</td>\n",
       "      <td>0.918149</td>\n",
       "      <td>0.985348</td>\n",
       "      <td>0.995516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.937716</td>\n",
       "      <td>0.989286</td>\n",
       "      <td>0.918216</td>\n",
       "      <td>0.996678</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.936396</td>\n",
       "      <td>0.953379</td>\n",
       "      <td>0.953730</td>\n",
       "      <td>0.953379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.982512</td>\n",
       "      <td>0.936877</td>\n",
       "      <td>0.914197</td>\n",
       "      <td>0.911901</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952087</td>\n",
       "      <td>0.941606</td>\n",
       "      <td>0.988971</td>\n",
       "      <td>0.988864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963696</td>\n",
       "      <td>0.947552</td>\n",
       "      <td>0.984014</td>\n",
       "      <td>0.921642</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.985447</td>\n",
       "      <td>0.951526</td>\n",
       "      <td>0.953379</td>\n",
       "      <td>0.953868</td>\n",
       "      <td>0.953412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.0</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.953379</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl     ml  \\\n",
       "precision    0.987220    0.889590    0.915625    0.902141    0.912621    1.0   \n",
       "recall       0.977848    0.989474    0.912773    0.921875    0.943144    1.0   \n",
       "f1-score     0.982512    0.936877    0.914197    0.911901    0.927632    1.0   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000  308.0   \n",
       "\n",
       "                  nhz          rj         syj          wl  ...         xxj  \\\n",
       "precision    0.950617    0.966292    0.992620    0.982301  ...    0.960526   \n",
       "recall       0.953560    0.918149    0.985348    0.995516  ...    0.966887   \n",
       "f1-score     0.952087    0.941606    0.988971    0.988864  ...    0.963696   \n",
       "support    323.000000  281.000000  273.000000  223.000000  ...  302.000000   \n",
       "\n",
       "                  yjf          zc         zdx         zjg          zl  \\\n",
       "precision    0.957597    0.978799    0.925094    0.993377    0.995798   \n",
       "recall       0.937716    0.989286    0.918216    0.996678    0.975309   \n",
       "f1-score     0.947552    0.984014    0.921642    0.995025    0.985447   \n",
       "support    289.000000  280.000000  269.000000  301.000000  243.000000   \n",
       "\n",
       "                  zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.967153  0.953379     0.954514      0.953952  \n",
       "recall       0.936396  0.953379     0.953730      0.953379  \n",
       "f1-score     0.951526  0.953379     0.953868      0.953412  \n",
       "support    283.000000  0.953379  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gb_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9249170595425179\n"
     ]
    }
   ],
   "source": [
    "pred = fit_models['knn'].predict(x_test)\n",
    "\n",
    "knn_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[306   0   0   0   0   0   5   1   0   0   0   0   0   4   0   0   0   0\n",
      "    0   0]\n",
      " [  0 277   0   0   0   0   0   1   0   0   3   0   1   3   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2 307   0   2   0   3   0   0   0   3   3   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   4   1 298   2   0   0   0   0   0   1   3   1   0   2   0   8   0\n",
      "    0   0]\n",
      " [  0   1   3   2 277   0   2   0   0   0   2   0   6   6   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 298   0   0   3   0   0   0   0   0   0   0   0   7\n",
      "    0   0]\n",
      " [  0   4   6   1   2   0 303   0   0   0   4   1   0   0   1   0   0   0\n",
      "    0   1]\n",
      " [  3  26   0   0   0   0   1 234   0   0   0   0   2  15   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   0 264   3   0   0   0   0   0   0   0   5\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   3 219   0   0   0   0   0   1   0   0\n",
      "    0   0]\n",
      " [  0   7   9   0   8   0   1   0   0   0 277   4   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   1   7   9   1   0   2   0   0   0  12 222   9   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   5   7   1  10   0   3   0   0   0  10   3 200   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   2   0   6   0   0   4   0   0   4   2   3 278   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1  15   2   0   1   0   0   0   0   3   0   0 264   0   2   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 276   0   2\n",
      "    2   0]\n",
      " [  0   0   0  32   0   0   1   0   0   0   1   0   0   1   7   0 224   0\n",
      "    0   3]\n",
      " [  0   0   0   0   0   7   0   0   1   0   0   0   0   0   0   0   0 293\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  12   0   0\n",
      "  231   0]\n",
      " [  0   0   1   4   0   0   1   0   0   0   5  10   2   0   6   0   5   0\n",
      "    0 249]]\n"
     ]
    }
   ],
   "source": [
    "knn_confusion = confusion_matrix(y_test, pred)\n",
    "print(knn_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fyc': {'precision': 0.9902912621359223, 'recall': 0.9683544303797469, 'f1-score': 0.9792000000000001, 'support': 316}, 'hy': {'precision': 0.8393939393939394, 'recall': 0.9719298245614035, 'f1-score': 0.9008130081300814, 'support': 285}, 'ljg': {'precision': 0.8924418604651163, 'recall': 0.956386292834891, 'f1-score': 0.9233082706766917, 'support': 321}, 'lqf': {'precision': 0.8232044198895028, 'recall': 0.93125, 'f1-score': 0.8739002932551321, 'support': 320}, 'lsl': {'precision': 0.8935483870967742, 'recall': 0.9264214046822743, 'f1-score': 0.909688013136289, 'support': 299}, 'ml': {'precision': 0.9738562091503268, 'recall': 0.9675324675324676, 'f1-score': 0.970684039087948, 'support': 308}, 'nhz': {'precision': 0.9380804953560371, 'recall': 0.9380804953560371, 'f1-score': 0.9380804953560372, 'support': 323}, 'rj': {'precision': 0.975, 'recall': 0.8327402135231317, 'f1-score': 0.8982725527831095, 'support': 281}, 'syj': {'precision': 0.974169741697417, 'recall': 0.967032967032967, 'f1-score': 0.9705882352941176, 'support': 273}, 'wl': {'precision': 0.9864864864864865, 'recall': 0.9820627802690582, 'f1-score': 0.9842696629213483, 'support': 223}, 'wq': {'precision': 0.860248447204969, 'recall': 0.8993506493506493, 'f1-score': 0.8793650793650795, 'support': 308}, 'wyc': {'precision': 0.8844621513944223, 'recall': 0.8409090909090909, 'f1-score': 0.8621359223300971, 'support': 264}, 'xch': {'precision': 0.8849557522123894, 'recall': 0.8368200836820083, 'f1-score': 0.8602150537634409, 'support': 239}, 'xxj': {'precision': 0.9055374592833876, 'recall': 0.9205298013245033, 'f1-score': 0.9129720853858785, 'support': 302}, 'yjf': {'precision': 0.9395017793594306, 'recall': 0.9134948096885813, 'f1-score': 0.9263157894736842, 'support': 289}, 'zc': {'precision': 0.9550173010380623, 'recall': 0.9857142857142858, 'f1-score': 0.9701230228471002, 'support': 280}, 'zdx': {'precision': 0.9333333333333333, 'recall': 0.8327137546468402, 'f1-score': 0.8801571709233792, 'support': 269}, 'zjg': {'precision': 0.9543973941368078, 'recall': 0.973421926910299, 'f1-score': 0.9638157894736842, 'support': 301}, 'zl': {'precision': 0.9914163090128756, 'recall': 0.9506172839506173, 'f1-score': 0.9705882352941176, 'support': 243}, 'zyf': {'precision': 0.9803149606299213, 'recall': 0.8798586572438163, 'f1-score': 0.9273743016759777, 'support': 283}, 'accuracy': 0.9249170595425179, 'macro avg': {'precision': 0.9287828844638563, 'recall': 0.9237610609796333, 'f1-score': 0.9250933510586596, 'support': 5727}, 'weighted avg': {'precision': 0.9273830581860769, 'recall': 0.9249170595425179, 'f1-score': 0.9249696825044511, 'support': 5727}}\n"
     ]
    }
   ],
   "source": [
    "knn_classification = classification_report(y_test, pred, output_dict=True)\n",
    "print(knn_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.839394</td>\n",
       "      <td>0.892442</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.893548</td>\n",
       "      <td>0.973856</td>\n",
       "      <td>0.93808</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.974170</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.939502</td>\n",
       "      <td>0.955017</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.954397</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.980315</td>\n",
       "      <td>0.924917</td>\n",
       "      <td>0.928783</td>\n",
       "      <td>0.927383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.971930</td>\n",
       "      <td>0.956386</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.926421</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.93808</td>\n",
       "      <td>0.832740</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.913495</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.879859</td>\n",
       "      <td>0.924917</td>\n",
       "      <td>0.923761</td>\n",
       "      <td>0.924917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.979200</td>\n",
       "      <td>0.900813</td>\n",
       "      <td>0.923308</td>\n",
       "      <td>0.873900</td>\n",
       "      <td>0.909688</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.93808</td>\n",
       "      <td>0.898273</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.984270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912972</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.880157</td>\n",
       "      <td>0.963816</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.924917</td>\n",
       "      <td>0.925093</td>\n",
       "      <td>0.924970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>323.00000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.924917</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl  \\\n",
       "precision    0.990291    0.839394    0.892442    0.823204    0.893548   \n",
       "recall       0.968354    0.971930    0.956386    0.931250    0.926421   \n",
       "f1-score     0.979200    0.900813    0.923308    0.873900    0.909688   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000   \n",
       "\n",
       "                   ml        nhz          rj         syj          wl  ...  \\\n",
       "precision    0.973856    0.93808    0.975000    0.974170    0.986486  ...   \n",
       "recall       0.967532    0.93808    0.832740    0.967033    0.982063  ...   \n",
       "f1-score     0.970684    0.93808    0.898273    0.970588    0.984270  ...   \n",
       "support    308.000000  323.00000  281.000000  273.000000  223.000000  ...   \n",
       "\n",
       "                  xxj         yjf          zc         zdx         zjg  \\\n",
       "precision    0.905537    0.939502    0.955017    0.933333    0.954397   \n",
       "recall       0.920530    0.913495    0.985714    0.832714    0.973422   \n",
       "f1-score     0.912972    0.926316    0.970123    0.880157    0.963816   \n",
       "support    302.000000  289.000000  280.000000  269.000000  301.000000   \n",
       "\n",
       "                   zl         zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.991416    0.980315  0.924917     0.928783      0.927383  \n",
       "recall       0.950617    0.879859  0.924917     0.923761      0.924917  \n",
       "f1-score     0.970588    0.927374  0.924917     0.925093      0.924970  \n",
       "support    243.000000  283.000000  0.924917  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8945346603806531\n"
     ]
    }
   ],
   "source": [
    "pred = fit_models['dt'].predict(x_test)\n",
    "\n",
    "dt_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(dt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[304   1   0   0   0   0   0   7   0   0   0   0   0   4   0   0   0   0\n",
      "    0   0]\n",
      " [  1 264   1   0   1   0   0   6   0   0   0   0   0  12   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0 270   1  11   0  10   0   0   0   4  18   5   1   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0 263   0   0   0   0   0   0   0  10   0   0  17   0  17   0\n",
      "    0  13]\n",
      " [  0   3   9   0 245   0   8   0   0   0  16   0  16   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 304   0   0   3   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0  13   0   9   0 285   0   0   0   6   4   4   2   0   0   0   0\n",
      "    0   0]\n",
      " [  6  15   0   0   0   0   0 252   0   0   0   0   0   8   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   0 258   7   0   0   0   0   0   0   0   7\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   7 211   0   0   0   0   0   0   0   5\n",
      "    0   0]\n",
      " [  0   4   3   0  24   0   4   0   0   0 260   1   9   3   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   9  10   1   0   5   0   0   0   4 227   2   0   4   0   0   0\n",
      "    0   2]\n",
      " [  0   2  12   0   7   0   3   0   0   0  14   1 199   0   1   0   0   0\n",
      "    0   0]\n",
      " [  3  18   1   0   3   0   1   7   0   0   0   0   1 268   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  11   0   0   0   0   0   0   0   1   0   0 254   0  12   0\n",
      "    0  11]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0   0   0   0   0 271   0   1\n",
      "    6   0]\n",
      " [  0   0   0  32   0   0   1   0   0   0   0   0   0   0   8   0 215   0\n",
      "    0  13]\n",
      " [  0   0   0   0   0   2   0   0   8   4   0   0   0   0   0   0   0 287\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   9   0   0\n",
      "  232   0]\n",
      " [  0   0   0  10   0   0   0   0   0   0   0   0   0   0   4   0  15   0\n",
      "    0 254]]\n"
     ]
    }
   ],
   "source": [
    "dt_confusion = confusion_matrix(y_test, pred)\n",
    "print(dt_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fyc': {'precision': 0.9681528662420382, 'recall': 0.9620253164556962, 'f1-score': 0.965079365079365, 'support': 316}, 'hy': {'precision': 0.8599348534201955, 'recall': 0.9263157894736842, 'f1-score': 0.8918918918918918, 'support': 285}, 'ljg': {'precision': 0.8490566037735849, 'recall': 0.8411214953271028, 'f1-score': 0.8450704225352114, 'support': 321}, 'lqf': {'precision': 0.8042813455657493, 'recall': 0.821875, 'f1-score': 0.8129829984544049, 'support': 320}, 'lsl': {'precision': 0.813953488372093, 'recall': 0.8193979933110368, 'f1-score': 0.8166666666666668, 'support': 299}, 'ml': {'precision': 0.990228013029316, 'recall': 0.987012987012987, 'f1-score': 0.9886178861788618, 'support': 308}, 'nhz': {'precision': 0.8990536277602523, 'recall': 0.8823529411764706, 'f1-score': 0.890625, 'support': 323}, 'rj': {'precision': 0.9264705882352942, 'recall': 0.896797153024911, 'f1-score': 0.9113924050632911, 'support': 281}, 'syj': {'precision': 0.9347826086956522, 'recall': 0.945054945054945, 'f1-score': 0.9398907103825138, 'support': 273}, 'wl': {'precision': 0.9336283185840708, 'recall': 0.9461883408071748, 'f1-score': 0.9398663697104678, 'support': 223}, 'wq': {'precision': 0.8552631578947368, 'recall': 0.8441558441558441, 'f1-score': 0.8496732026143792, 'support': 308}, 'wyc': {'precision': 0.8664122137404581, 'recall': 0.8598484848484849, 'f1-score': 0.8631178707224334, 'support': 264}, 'xch': {'precision': 0.8432203389830508, 'recall': 0.8326359832635983, 'f1-score': 0.8378947368421052, 'support': 239}, 'xxj': {'precision': 0.8933333333333333, 'recall': 0.8874172185430463, 'f1-score': 0.8903654485049834, 'support': 302}, 'yjf': {'precision': 0.8819444444444444, 'recall': 0.8788927335640139, 'f1-score': 0.8804159445407279, 'support': 289}, 'zc': {'precision': 0.9678571428571429, 'recall': 0.9678571428571429, 'f1-score': 0.9678571428571429, 'support': 280}, 'zdx': {'precision': 0.8301158301158301, 'recall': 0.7992565055762082, 'f1-score': 0.8143939393939394, 'support': 269}, 'zjg': {'precision': 0.9534883720930233, 'recall': 0.9534883720930233, 'f1-score': 0.9534883720930233, 'support': 301}, 'zl': {'precision': 0.9747899159663865, 'recall': 0.9547325102880658, 'f1-score': 0.9646569646569646, 'support': 243}, 'zyf': {'precision': 0.8639455782312925, 'recall': 0.8975265017667845, 'f1-score': 0.8804159445407279, 'support': 283}, 'accuracy': 0.8945346603806531, 'macro avg': {'precision': 0.8954956320668972, 'recall': 0.8951976629300109, 'f1-score': 0.8952181641364552, 'support': 5727}, 'weighted avg': {'precision': 0.8947875747114181, 'recall': 0.8945346603806531, 'f1-score': 0.8945344482954737, 'support': 5727}}\n"
     ]
    }
   ],
   "source": [
    "dt_classification = classification_report(y_test, pred, output_dict=True)\n",
    "print(dt_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.859935</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.804281</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.990228</td>\n",
       "      <td>0.899054</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.933628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.881944</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0.830116</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.974790</td>\n",
       "      <td>0.863946</td>\n",
       "      <td>0.894535</td>\n",
       "      <td>0.895496</td>\n",
       "      <td>0.894788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.819398</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.896797</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.946188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.878893</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0.799257</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.954733</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>0.894535</td>\n",
       "      <td>0.895198</td>\n",
       "      <td>0.894535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.965079</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.812983</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.988618</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.939891</td>\n",
       "      <td>0.939866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890365</td>\n",
       "      <td>0.880416</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.964657</td>\n",
       "      <td>0.880416</td>\n",
       "      <td>0.894535</td>\n",
       "      <td>0.895218</td>\n",
       "      <td>0.894534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.894535</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl  \\\n",
       "precision    0.968153    0.859935    0.849057    0.804281    0.813953   \n",
       "recall       0.962025    0.926316    0.841121    0.821875    0.819398   \n",
       "f1-score     0.965079    0.891892    0.845070    0.812983    0.816667   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000   \n",
       "\n",
       "                   ml         nhz          rj         syj          wl  ...  \\\n",
       "precision    0.990228    0.899054    0.926471    0.934783    0.933628  ...   \n",
       "recall       0.987013    0.882353    0.896797    0.945055    0.946188  ...   \n",
       "f1-score     0.988618    0.890625    0.911392    0.939891    0.939866  ...   \n",
       "support    308.000000  323.000000  281.000000  273.000000  223.000000  ...   \n",
       "\n",
       "                  xxj         yjf          zc         zdx         zjg  \\\n",
       "precision    0.893333    0.881944    0.967857    0.830116    0.953488   \n",
       "recall       0.887417    0.878893    0.967857    0.799257    0.953488   \n",
       "f1-score     0.890365    0.880416    0.967857    0.814394    0.953488   \n",
       "support    302.000000  289.000000  280.000000  269.000000  301.000000   \n",
       "\n",
       "                   zl         zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.974790    0.863946  0.894535     0.895496      0.894788  \n",
       "recall       0.954733    0.897527  0.894535     0.895198      0.894535  \n",
       "f1-score     0.964657    0.880416  0.894535     0.895218      0.894534  \n",
       "support    243.000000  283.000000  0.894535  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dt_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SupportVectorMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9158372620918457\n"
     ]
    }
   ],
   "source": [
    "pred = fit_models['svc'].predict(x_test)\n",
    "\n",
    "svc_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "print(svc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[312   1   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0 275   0   0   0   0   0   2   0   0   0   0   0   8   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1 279   0   6   0   4   0   0   0   7  10  13   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1 287   0   0   0   0   0   0   0   7   0   0   9   0   8   0\n",
      "    0   8]\n",
      " [  0   4  14   0 241   0   6   0   0   0  10   5  16   3   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 307   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1  13   0   2   0 301   0   0   0   6   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   4   1   0   0   0   0 273   0   0   0   0   0   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   0 271   1   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 223   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   7  23   0   2   0   2   0   0   0 249  10  12   3   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  14   0   0   0   1   0   0   0   7 241   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2  19   0  10   0   0   0   0   0  16   4 188   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1  19   1   0   2   0   0   0   0   0   5   1   0 273   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  27   0   0   0   0   0   0   0   1   0   0 252   0   6   0\n",
      "    0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 274   0   0\n",
      "    6   0]\n",
      " [  0   0   0  33   0   0   0   0   0   0   0   0   0   0  12   0 214   0\n",
      "    0  10]\n",
      " [  0   0   0   0   0  11   0   0   2   0   0   0   0   0   0   1   0 287\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  243   0]\n",
      " [  0   0   0   9   0   0   0   0   0   0   0   0   0   0  11   0   8   0\n",
      "    0 255]]\n"
     ]
    }
   ],
   "source": [
    "svc_confusion = confusion_matrix(y_test, pred)\n",
    "print(svc_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fyc': {'precision': 0.9936305732484076, 'recall': 0.9873417721518988, 'f1-score': 0.9904761904761905, 'support': 316}, 'hy': {'precision': 0.8757961783439491, 'recall': 0.9649122807017544, 'f1-score': 0.9181969949916527, 'support': 285}, 'ljg': {'precision': 0.7643835616438356, 'recall': 0.8691588785046729, 'f1-score': 0.8134110787172011, 'support': 321}, 'lqf': {'precision': 0.8061797752808989, 'recall': 0.896875, 'f1-score': 0.849112426035503, 'support': 320}, 'lsl': {'precision': 0.9163498098859315, 'recall': 0.8060200668896321, 'f1-score': 0.8576512455516013, 'support': 299}, 'ml': {'precision': 0.9623824451410659, 'recall': 0.9967532467532467, 'f1-score': 0.9792663476874004, 'support': 308}, 'nhz': {'precision': 0.9585987261146497, 'recall': 0.9318885448916409, 'f1-score': 0.945054945054945, 'support': 323}, 'rj': {'precision': 0.9820143884892086, 'recall': 0.9715302491103203, 'f1-score': 0.9767441860465116, 'support': 281}, 'syj': {'precision': 0.9890510948905109, 'recall': 0.9926739926739927, 'f1-score': 0.9908592321755026, 'support': 273}, 'wl': {'precision': 0.9955357142857143, 'recall': 1.0, 'f1-score': 0.9977628635346756, 'support': 223}, 'wq': {'precision': 0.83, 'recall': 0.8084415584415584, 'f1-score': 0.819078947368421, 'support': 308}, 'wyc': {'precision': 0.8637992831541219, 'recall': 0.9128787878787878, 'f1-score': 0.8876611418047882, 'support': 264}, 'xch': {'precision': 0.8173913043478261, 'recall': 0.7866108786610879, 'f1-score': 0.8017057569296375, 'support': 239}, 'xxj': {'precision': 0.9413793103448276, 'recall': 0.9039735099337748, 'f1-score': 0.9222972972972973, 'support': 302}, 'yjf': {'precision': 0.8873239436619719, 'recall': 0.8719723183391004, 'f1-score': 0.8795811518324607, 'support': 289}, 'zc': {'precision': 0.9963636363636363, 'recall': 0.9785714285714285, 'f1-score': 0.9873873873873874, 'support': 280}, 'zdx': {'precision': 0.9067796610169492, 'recall': 0.7955390334572491, 'f1-score': 0.8475247524752476, 'support': 269}, 'zjg': {'precision': 1.0, 'recall': 0.9534883720930233, 'f1-score': 0.9761904761904763, 'support': 301}, 'zl': {'precision': 0.9759036144578314, 'recall': 1.0, 'f1-score': 0.9878048780487805, 'support': 243}, 'zyf': {'precision': 0.9239130434782609, 'recall': 0.901060070671378, 'f1-score': 0.9123434704830053, 'support': 283}, 'accuracy': 0.9158372620918457, 'macro avg': {'precision': 0.9193388032074801, 'recall': 0.9164844994862273, 'f1-score': 0.9170055385044342, 'support': 5727}, 'weighted avg': {'precision': 0.917970189462195, 'recall': 0.9158372620918457, 'f1-score': 0.915967850511605, 'support': 5727}}\n"
     ]
    }
   ],
   "source": [
    "svc_classification = classification_report(y_test, pred, output_dict=True)\n",
    "print(svc_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyc</th>\n",
       "      <th>hy</th>\n",
       "      <th>ljg</th>\n",
       "      <th>lqf</th>\n",
       "      <th>lsl</th>\n",
       "      <th>ml</th>\n",
       "      <th>nhz</th>\n",
       "      <th>rj</th>\n",
       "      <th>syj</th>\n",
       "      <th>wl</th>\n",
       "      <th>...</th>\n",
       "      <th>xxj</th>\n",
       "      <th>yjf</th>\n",
       "      <th>zc</th>\n",
       "      <th>zdx</th>\n",
       "      <th>zjg</th>\n",
       "      <th>zl</th>\n",
       "      <th>zyf</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.875796</td>\n",
       "      <td>0.764384</td>\n",
       "      <td>0.806180</td>\n",
       "      <td>0.916350</td>\n",
       "      <td>0.962382</td>\n",
       "      <td>0.958599</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>0.989051</td>\n",
       "      <td>0.995536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941379</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>0.906780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.915837</td>\n",
       "      <td>0.919339</td>\n",
       "      <td>0.917970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.806020</td>\n",
       "      <td>0.996753</td>\n",
       "      <td>0.931889</td>\n",
       "      <td>0.971530</td>\n",
       "      <td>0.992674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903974</td>\n",
       "      <td>0.871972</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.795539</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901060</td>\n",
       "      <td>0.915837</td>\n",
       "      <td>0.916484</td>\n",
       "      <td>0.915837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.918197</td>\n",
       "      <td>0.813411</td>\n",
       "      <td>0.849112</td>\n",
       "      <td>0.857651</td>\n",
       "      <td>0.979266</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.990859</td>\n",
       "      <td>0.997763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922297</td>\n",
       "      <td>0.879581</td>\n",
       "      <td>0.987387</td>\n",
       "      <td>0.847525</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.912343</td>\n",
       "      <td>0.915837</td>\n",
       "      <td>0.917006</td>\n",
       "      <td>0.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.915837</td>\n",
       "      <td>5727.000000</td>\n",
       "      <td>5727.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fyc          hy         ljg         lqf         lsl  \\\n",
       "precision    0.993631    0.875796    0.764384    0.806180    0.916350   \n",
       "recall       0.987342    0.964912    0.869159    0.896875    0.806020   \n",
       "f1-score     0.990476    0.918197    0.813411    0.849112    0.857651   \n",
       "support    316.000000  285.000000  321.000000  320.000000  299.000000   \n",
       "\n",
       "                   ml         nhz          rj         syj          wl  ...  \\\n",
       "precision    0.962382    0.958599    0.982014    0.989051    0.995536  ...   \n",
       "recall       0.996753    0.931889    0.971530    0.992674    1.000000  ...   \n",
       "f1-score     0.979266    0.945055    0.976744    0.990859    0.997763  ...   \n",
       "support    308.000000  323.000000  281.000000  273.000000  223.000000  ...   \n",
       "\n",
       "                  xxj         yjf          zc         zdx         zjg  \\\n",
       "precision    0.941379    0.887324    0.996364    0.906780    1.000000   \n",
       "recall       0.903974    0.871972    0.978571    0.795539    0.953488   \n",
       "f1-score     0.922297    0.879581    0.987387    0.847525    0.976190   \n",
       "support    302.000000  289.000000  280.000000  269.000000  301.000000   \n",
       "\n",
       "                   zl         zyf  accuracy    macro avg  weighted avg  \n",
       "precision    0.975904    0.923913  0.915837     0.919339      0.917970  \n",
       "recall       1.000000    0.901060  0.915837     0.916484      0.915837  \n",
       "f1-score     0.987805    0.912343  0.915837     0.917006      0.915968  \n",
       "support    243.000000  283.000000  0.915837  5727.000000   5727.000000  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(svc_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 0.8700890518596124\n",
      "RC accuracy: 0.7178278330714161\n",
      "RF accuracy: 0.9924917059542517\n",
      "GB accuracy: 0.9533787323205867\n",
      "KNN accuracy: 0.9249170595425179\n",
      "DT accuracy: 0.8945346603806531\n",
      "SVC accuracy: 0.9158372620918457\n"
     ]
    }
   ],
   "source": [
    "labels = ['LR','RC','RF','GB', 'KNN','DT', 'SVC']\n",
    "accuracy = [lr_acc,rc_acc, rf_acc, gb_acc, knn_acc,dt_acc,svc_acc]\n",
    "\n",
    "for acc, label in zip(accuracy, labels):\n",
    "    print(f'{label} accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "{'precision': 0.8693339234884881, 'recall': 0.8700890518596124, 'f1-score': 0.8692440619552597, 'support': 5727}\n",
      "RC\n",
      "{'precision': 0.7245162547570262, 'recall': 0.7178278330714161, 'f1-score': 0.7080101222977263, 'support': 5727}\n",
      "RF\n",
      "{'precision': 0.9925100737562886, 'recall': 0.9924917059542517, 'f1-score': 0.992488471823071, 'support': 5727}\n",
      "GB\n",
      "{'precision': 0.9539524281148659, 'recall': 0.9533787323205867, 'f1-score': 0.9534121527239778, 'support': 5727}\n",
      "KNN\n",
      "{'precision': 0.9273830581860769, 'recall': 0.9249170595425179, 'f1-score': 0.9249696825044511, 'support': 5727}\n",
      "DT\n",
      "{'precision': 0.8947875747114181, 'recall': 0.8945346603806531, 'f1-score': 0.8945344482954737, 'support': 5727}\n",
      "SVC\n",
      "{'precision': 0.917970189462195, 'recall': 0.9158372620918457, 'f1-score': 0.915967850511605, 'support': 5727}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reports = [lr_classification,rc_classification,rf_classification,gb_classification, knn_classification,dt_classification, svc_classification]\n",
    "\n",
    "for i in ['weighted avg']:\n",
    "    for report, label in zip(reports, labels):\n",
    "        print(f'{label}')\n",
    "        print(report.get(f'{i}'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to the results, RF has the best performance. Therefor, we choose RF to be the detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GaitRecognition.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
